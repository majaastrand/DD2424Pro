############################################
#batch size 32
model_tuned = models.resnet18(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 2
model_tuned.fc = nn.Linear(num_features, output_size)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-3)

train_losses: 
 [0.3510011621170349, 0.26032618044010886, 0.25436222806937725, 0.21521347959275075, 0.22138773407752008, 0.2114562417940007, 0.18714270633829516, 0.20258610180654543, 0.18698855041615708, 0.18020643595248292, 0.16912329806446355, 0.17804855861457278, 0.17255475781507187, 0.15452718429982998, 0.17412213667974633, 0.16055537520043145, 0.15592570399160438, 0.1535308074816472, 0.15020250614360675, 0.150171116802652, 0.14739699114513935, 0.14638867519669613, 0.1380578110348819, 0.1456947586742947, 0.1404809982258048, 0.14399946472290096, 0.1385496152519282, 0.12802851395278103, 0.13486035627553242, 0.1270550491712749, 0.12752563659866425, 0.12522609571166857, 0.11901937894060113, 0.12697673828925116, 0.1304830802208174, 0.12984929016305452, 0.11514548420232568, 0.1223145263679957, 0.12396237625689606, 0.12007777279491927, 0.11655047418034009, 0.10667265343379839, 0.11420808427751401, 0.11363648404340959, 0.11408954893577346, 0.11607518941900656, 0.1309035300142123, 0.11012544298295472, 0.1143411653919633, 0.10988290125535706] 
 train_accs 
 [0.8468926553672316, 0.884180790960452, 0.8922787193973635, 0.9071563088512241, 0.8971751412429378, 0.9092278719397363, 0.9163841807909604, 0.9065913370998117, 0.9150659133709981, 0.9203389830508475, 0.9229755178907721, 0.9244821092278719, 0.9233521657250471, 0.9338983050847458, 0.9258003766478342, 0.9297551789077213, 0.9286252354048964, 0.9333333333333333, 0.9369114877589454, 0.9338983050847458, 0.9378531073446328, 0.9376647834274953, 0.9380414312617702, 0.9333333333333333, 0.9335216572504708, 0.9365348399246705, 0.9408662900188324, 0.9446327683615819, 0.939924670433145, 0.9418079096045198, 0.944256120527307, 0.9433145009416196, 0.9487758945386064, 0.9406779661016949, 0.9418079096045198, 0.9423728813559322, 0.951035781544256, 0.9451977401129943, 0.9461393596986817, 0.947457627118644, 0.948210922787194, 0.952165725047081, 0.948210922787194, 0.9465160075329567, 0.9491525423728814, 0.9470809792843691, 0.9418079096045198, 0.9493408662900188, 0.9485875706214689, 0.9538606403013182] 
 val_accs 
 [0.9089026915113871, 0.94824016563147, 0.9523809523809524, 0.9523809523809524, 0.9461697722567288, 0.955831608005521, 0.9523809523809524, 0.9675638371290546, 0.9744651483781919, 0.971704623878537, 0.94824016563147, 0.9723947550034506, 0.9744651483781919, 0.9572118702553485, 0.9730848861283644, 0.9710144927536232, 0.971704623878537, 0.9599723947550035, 0.9786059351276742, 0.9696342305037957, 0.9661835748792271, 0.9661835748792271, 0.9440993788819876, 0.9641131815044859, 0.9661835748792271, 0.9627329192546584, 0.9772256728778468, 0.9744651483781919, 0.9737750172532782, 0.9806763285024155, 0.9779158040027606, 0.9744651483781919, 0.9648033126293996, 0.961352657004831, 0.9730848861283644, 0.9772256728778468, 0.955831608005521, 0.9779158040027606, 0.9799861973775017, 0.9730848861283644, 0.9786059351276742, 0.9806763285024155, 0.9751552795031057, 0.9592822636300897, 0.9710144927536232, 0.9579020013802623, 0.9751552795031057, 0.9772256728778468, 0.9661835748792271, 0.9765355417529331] 
 val_losses 
 [0.2508146255222465, 0.13766696564776063, 0.12804546151143095, 0.1330847347693825, 0.12058262697956412, 0.11808999958451326, 0.1301547985824739, 0.08508290798551794, 0.07714390997396328, 0.08408252209980295, 0.13735843441089818, 0.06868800306994804, 0.06611655010045439, 0.13635595132557585, 0.07643874631288382, 0.06587772186475326, 0.07860298108102547, 0.10061350878677733, 0.06907100901984609, 0.081794916431685, 0.08028563663743955, 0.09084911314285958, 0.19115293747761522, 0.08401145948112536, 0.07909295540315847, 0.08506989562363358, 0.05977909795308757, 0.06115718515811336, 0.06894945107447659, 0.05428831542799027, 0.05875642873537055, 0.061021582278549306, 0.10002333070604635, 0.12122916157458304, 0.06441607330382652, 0.05665522451672235, 0.12847725781075414, 0.0601694319064636, 0.06608586700786138, 0.06707940711154557, 0.05589127381961456, 0.05675974748019589, 0.07017738252743697, 0.15098744385160398, 0.07501150706036641, 0.13673550734067305, 0.07719373663410473, 0.08333027083683808, 0.12268835827885398, 0.0702980449905245] 
 test_accs 
 [0.9778130054473877] 
 test_losses 
 [0.06671118738997592]  


 ###########################################
 #batch size 64
model_tuned = models.resnet18(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 2
model_tuned.fc = nn.Linear(num_features, output_size)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-3)

 train_losses: 
 [0.20797280587831235, 0.22190235659564284, 0.19191008032827503, 0.19460056874823883, 0.17240203986060149, 0.15540944961673123, 0.16425774643537913, 0.15939794286047224, 0.14696078519363187, 0.14749948842882438, 0.14138395292666897, 0.14954614264929136, 0.13830436565781717, 0.13045751315501225, 0.11943693724504748, 0.11929977389505017, 0.14451950012290546, 0.1260957137676282, 0.12845368860692852, 0.12389187721602211, 0.11965012980270745, 0.11851999215823783, 0.11984297722129049, 0.11696239025691584, 0.10761430212165003, 0.11460837727998385, 0.12100485982952144, 0.10110221043257166, 0.10376233129627063, 0.11962329438850705, 0.10820268223626914, 0.10859874097416405, 0.10843101644190467, 0.10173850347991269, 0.09920388519651696, 0.1036720533520264, 0.10801237335958275, 0.11013777181365844, 0.09576184853714963, 0.10610339967656719, 0.10558267465868014, 0.09796691925007071, 0.09712542485158097, 0.0953578300437348, 0.09977235318689472, 0.08703430463365243, 0.09979320749387903, 0.10161869649103582, 0.0875593800385344, 0.09608064372436251] 
 train_accs 
 [0.9069679849340866, 0.9009416195856874, 0.9103578154425612, 0.9124293785310734, 0.9214689265536723, 0.9322033898305084, 0.9259887005649717, 0.9265536723163842, 0.932391713747646, 0.9365348399246705, 0.939924670433145, 0.9322033898305084, 0.9357815442561205, 0.943879472693032, 0.9450094161958569, 0.9465160075329567, 0.9333333333333333, 0.9433145009416196, 0.9414312617702448, 0.9427495291902072, 0.9470809792843691, 0.9495291902071563, 0.9450094161958569, 0.9463276836158192, 0.9514124293785311, 0.9502824858757062, 0.9451977401129943, 0.9585687382297552, 0.9532956685499058, 0.9523540489642185, 0.9512241054613936, 0.9523540489642185, 0.9531073446327684, 0.9536723163841808, 0.9570621468926553, 0.9540489642184558, 0.9527306967984934, 0.9506591337099811, 0.9593220338983051, 0.9519774011299434, 0.9549905838041431, 0.9563088512241055, 0.96045197740113, 0.9602636534839925, 0.9578154425612052, 0.9619585687382297, 0.955743879472693, 0.9525423728813559, 0.9591337099811676, 0.9566854990583804] 
 val_accs 
 [0.927536231884058, 0.9302967563837129, 0.9503105590062112, 0.9530710835058661, 0.9503105590062112, 0.9682539682539683, 0.8916494133885439, 0.9420289855072463, 0.9723947550034506, 0.9682539682539683, 0.9682539682539683, 0.9572118702553485, 0.979296066252588, 0.9786059351276742, 0.9737750172532782, 0.9523809523809524, 0.9648033126293996, 0.9641131815044859, 0.9758454106280193, 0.9537612146307799, 0.9751552795031057, 0.9627329192546584, 0.9765355417529331, 0.9799861973775017, 0.9696342305037957, 0.9779158040027606, 0.9730848861283644, 0.979296066252588, 0.9751552795031057, 0.979296066252588, 0.9806763285024155, 0.9765355417529331, 0.9765355417529331, 0.9786059351276742, 0.9827467218771567, 0.9620427881297446, 0.9827467218771567, 0.9779158040027606, 0.9730848861283644, 0.9744651483781919, 0.9737750172532782, 0.9855072463768116, 0.9779158040027606, 0.9827467218771567, 0.9834368530020704, 0.9799861973775017, 0.9772256728778468, 0.9813664596273292, 0.9786059351276742, 0.9779158040027606] 
 val_losses 
 [0.17236988807933917, 0.15037308158217996, 0.10699082192180073, 0.13148876717166294, 0.1194000262240034, 0.0947769423181884, 0.3001156374143682, 0.18048955392146457, 0.0751926197912711, 0.07851729033999479, 0.08560028897946748, 0.09267718806217526, 0.062257130015217245, 0.06619466460721915, 0.06223808445185526, 0.1262143015079946, 0.09602466978909148, 0.10494443490391686, 0.06631785498198, 0.10743904245401598, 0.0847822452224971, 0.08431874593659423, 0.05762962669936273, 0.05072759415278195, 0.08568194111599603, 0.057114158913215494, 0.07139811612372567, 0.06662419354035329, 0.1006855112754369, 0.06265744232695378, 0.06861192426079302, 0.06664528072990986, 0.06365435891074506, 0.07032991746688626, 0.04323845581917042, 0.09903641783981343, 0.054654007364936, 0.07416916413912697, 0.09908862431257902, 0.07505099749445833, 0.07883157904000838, 0.0511480351052587, 0.06986630138194894, 0.04913541201561216, 0.050155801442757074, 0.054047704446132716, 0.0655891349843817, 0.05995895067105177, 0.0570851624952957, 0.06557297265430909] 
 test_accs 
 [0.9825673699378967] 
 test_losses 
 [0.03824418721198091]


 #############################################
 #batch size 64
model_tuned = models.resnet18(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 2
model_tuned.fc = nn.Linear(num_features, output_size)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=2e-3)

training itr: 00 	 loss: 0.52 	 acc : 0.78
validation itr: 00 	 loss: 0.28 	 acc : 0.87
training itr: 01 	 loss: 0.32 	 acc : 0.85
validation itr: 01 	 loss: 0.25 	 acc : 0.89
training itr: 02 	 loss: 0.28 	 acc : 0.87
validation itr: 02 	 loss: 0.17 	 acc : 0.92
training itr: 03 	 loss: 0.25 	 acc : 0.88
validation itr: 03 	 loss: 0.19 	 acc : 0.92
training itr: 04 	 loss: 0.22 	 acc : 0.90
validation itr: 04 	 loss: 0.14 	 acc : 0.94
training itr: 05 	 loss: 0.23 	 acc : 0.89
validation itr: 05 	 loss: 0.18 	 acc : 0.93
training itr: 06 	 loss: 0.22 	 acc : 0.90
validation itr: 06 	 loss: 0.11 	 acc : 0.96
training itr: 07 	 loss: 0.20 	 acc : 0.90
validation itr: 07 	 loss: 0.11 	 acc : 0.95
training itr: 08 	 loss: 0.20 	 acc : 0.91
validation itr: 08 	 loss: 0.13 	 acc : 0.95
training itr: 09 	 loss: 0.19 	 acc : 0.91
validation itr: 09 	 loss: 0.13 	 acc : 0.95
training itr: 10 	 loss: 0.19 	 acc : 0.92
validation itr: 10 	 loss: 0.15 	 acc : 0.94
training itr: 11 	 loss: 0.18 	 acc : 0.92
validation itr: 11 	 loss: 0.16 	 acc : 0.94
training itr: 12 	 loss: 0.18 	 acc : 0.92
validation itr: 12 	 loss: 0.11 	 acc : 0.96
training itr: 13 	 loss: 0.16 	 acc : 0.92
validation itr: 13 	 loss: 0.12 	 acc : 0.96
training itr: 14 	 loss: 0.19 	 acc : 0.92
validation itr: 14 	 loss: 0.17 	 acc : 0.94
training itr: 15 	 loss: 0.16 	 acc : 0.93
validation itr: 15 	 loss: 0.10 	 acc : 0.96
training itr: 16 	 loss: 0.17 	 acc : 0.92
validation itr: 16 	 loss: 0.16 	 acc : 0.94
training itr: 17 	 loss: 0.15 	 acc : 0.93
validation itr: 17 	 loss: 0.11 	 acc : 0.96
training itr: 18 	 loss: 0.18 	 acc : 0.92
validation itr: 18 	 loss: 0.08 	 acc : 0.97
training itr: 19 	 loss: 0.17 	 acc : 0.92
validation itr: 19 	 loss: 0.08 	 acc : 0.97
training itr: 20 	 loss: 0.16 	 acc : 0.93
validation itr: 20 	 loss: 0.20 	 acc : 0.92
training itr: 21 	 loss: 0.16 	 acc : 0.92
validation itr: 21 	 loss: 0.11 	 acc : 0.96
training itr: 22 	 loss: 0.16 	 acc : 0.93
validation itr: 22 	 loss: 0.08 	 acc : 0.97
training itr: 23 	 loss: 0.14 	 acc : 0.94
validation itr: 23 	 loss: 0.09 	 acc : 0.96


###################################################
model_tuned = models.resnet18(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 2
model_tuned.fc = nn.Linear(num_features, output_size)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-4)

train_losses: 
 [0.20486133139573473, 0.15692047516617175, 0.13950827322661766, 0.12168083508304284, 0.12791336954986982, 0.11781825332598947, 0.11915160072388623, 0.13032363084637738, 0.11449886161392019, 0.11035100213355488, 0.0952091937347994, 0.09486737311054758, 0.10693333504507546] 
 train_accs 
 [0.907909604519774, 0.9295668549905838, 0.940677966101695, 0.9459510357815443, 0.9470809792843691, 0.9480225988700565, 0.9472693032015066, 0.9448210922787194, 0.9531073446327684, 0.9516007532956685, 0.9574387947269303, 0.9589453860640301, 0.9555555555555556] 
 val_accs 
 [0.979296066252588, 0.9751552795031055, 0.9806763285024155, 0.9820565907522429, 0.9779158040027606, 0.9806763285024155, 0.9406487232574189, 0.9868875086266391, 0.9737750172532781, 0.9813664596273292, 0.9744651483781919, 0.9799861973775017, 0.9779158040027606] 
 val_losses 
 [0.05404171728374137, 0.07716587020034128, 0.0512531037018824, 0.04329991594517412, 0.059639172128474326, 0.049764551621462615, 0.17417185129359972, 0.038924639553199296, 0.08074455418038452, 0.04937537017762352, 0.07604802459005326, 0.054342193447543194, 0.062270880973106665] 
 test_accs 
 [] 
 test_losses 
 []