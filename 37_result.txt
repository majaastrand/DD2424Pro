#######################################################

model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
model_tuned.fc = nn.Linear(num_features, output_size)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-4)
max_iters = 50
BatchSize = 64

Whatsapp: 37_cat_result1

train_losses: 
 [1.5254684220149548, 1.0702190748592355, 0.9506422183537613, 0.8496512558141238, 0.8024238312972762, 0.7432556293864445, 0.7286567694441993, 0.6941837573457115, 0.6525210202984909, 0.6580089964980961, 0.6313695001307146, 0.5633166527803426, 0.5918318673057881, 0.5429327297561037, 0.5311368082441845, 0.5268513549231598, 0.5170827881366084, 0.525401610924307, 0.48401060681977387, 0.49514346826196365, 0.4932982527923879, 0.4408440991878878, 0.456939261593933, 0.4601105260738364, 0.4255319821770027, 0.45555944343177457, 0.4254526901134482, 0.4398812541344879, 0.42217811425803525, 0.4199071385928668, 0.4245383836507613, 0.4111342691951082, 0.40221960863353484, 0.3607837883705145, 0.39053667066453135, 0.40530373710398515, 0.340009963729081, 0.36302705298120996, 0.38581913596700534, 0.36749643497658807, 0.38086543552007035, 0.3631773729335404, 0.32980281312799414, 0.3665290254312989, 0.3338199936181929, 0.35712082410909735, 0.36806181801536336, 0.3488420595610133, 0.3177784274275323, 0.32039062182108563] 
 train_accs 
 [0.565738592420727, 0.684261407579273, 0.720030935808198, 0.7407192575406033, 0.7627610208816705, 0.772815158546017, 0.7782289249806652, 0.7907965970610983, 0.7989172467130704, 0.8010440835266822, 0.8095514307811292, 0.8265661252900233, 0.8234725444702243, 0.8364269141531323, 0.837200309358082, 0.8418406805877804, 0.8445475638051044, 0.8447409126063419, 0.8495746326372777, 0.8522815158546018, 0.85015467904099, 0.8654292343387472, 0.8625290023201857, 0.8607888631090488, 0.8721964423820573, 0.8607888631090488, 0.8745166279969064, 0.8681361175560712, 0.8725831399845322, 0.8772235112142305, 0.8712296983758702, 0.8737432327919568, 0.881477184841454, 0.8895978344934262, 0.8793503480278423, 0.8822505800464038, 0.8975251353441609, 0.8876643464810519, 0.8863109048723898, 0.8865042536736273, 0.8830239752513535, 0.8923047177107503, 0.9021655065738593, 0.887277648878577, 0.9000386697602475, 0.8952049497293117, 0.8932714617169374, 0.8895978344934262, 0.9068058778035577, 0.9013921113689095] 
 val_accs 
 [0.6006756756756757, 0.7283783783783784, 0.7391891891891892, 0.770945945945946, 0.8297297297297298, 0.8195945945945946, 0.7817567567567568, 0.775, 0.8040540540540541, 0.8263513513513514, 0.8175675675675677, 0.8391891891891893, 0.8574324324324325, 0.8148648648648649, 0.8371621621621622, 0.8587837837837838, 0.8135135135135135, 0.8567567567567568, 0.841891891891892, 0.8432432432432433, 0.827027027027027, 0.8472972972972973, 0.8527027027027028, 0.8655405405405406, 0.8412162162162162, 0.8432432432432433, 0.8560810810810812, 0.8743243243243244, 0.8277027027027027, 0.847972972972973, 0.8641891891891892, 0.870945945945946, 0.8466216216216217, 0.8756756756756757, 0.8554054054054054, 0.8621621621621622, 0.8621621621621622, 0.8648648648648649, 0.8601351351351352, 0.8628378378378379, 0.8601351351351352, 0.8641891891891892, 0.8777027027027028, 0.8364864864864865, 0.8682432432432433, 0.8533783783783784, 0.8540540540540541, 0.8878378378378379, 0.8601351351351352, 0.8500000000000001] 
 val_losses 
 [1.3223057753330953, 0.9271454875533646, 0.9196885440800641, 0.7237158698004645, 0.630248101337536, 0.5931939994966662, 0.7622319672558758, 0.7441906181541649, 0.6231062760224213, 0.5806758505267066, 0.6090866333729512, 0.6151920849809775, 0.5208866972778294, 0.7005189721648758, 0.5380892167421611, 0.4932623801199166, 0.6134568127828676, 0.5076016020130467, 0.5699292434228433, 0.5653400078013137, 0.6341637664550059, 0.5354996113383488, 0.5897187597042806, 0.46177821304347066, 0.5953852279766186, 0.5691071470041533, 0.54186325508195, 0.45736214249722057, 0.6435585676012813, 0.6815601915926547, 0.5054964031722095, 0.4593945002837761, 0.607684648359144, 0.4783365991469976, 0.5259388549907787, 0.5371230368678634, 0.5339955464206837, 0.537695052897608, 0.5245678125201045, 0.4904313811579266, 0.5567064816081846, 0.5180163634789957, 0.48072868070086916, 0.6795897364616394, 0.5696048630250466, 0.5894963683308782, 0.549471936354766, 0.44373222492836617, 0.5280232693697955, 0.5720133472133327] 
 test_accs 
 [0.868563711643219] 
 test_losses 
 [0.5012704818067835]


 #################################################
 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter_size = 1024
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-4)
max_iters = 50
BatchSize = 64

train_losses: 
 [1.7284754476893898, 1.1659689965583702, 1.0533720795166004, 0.9198579899765038, 0.8707959622905315, 0.8282679738873027, 0.7913538184815013, 0.7249809625253877, 0.7596716783070694, 0.6822697795921763, 0.6804892577962736, 0.6725739069622981, 0.6322218882004973, 0.5931886758623617, 0.5652876345344228, 0.5711852621405233, 0.6053170411050182, 0.5468978282101654, 0.5455404012957379, 0.5365178937701781, 0.5075468724767828, 0.4955561408817722, 0.4916843707858364, 0.48291944026117256, 0.5035138776020218, 0.48382044702837473, 0.4782447912208073, 0.4625487285626552, 0.46368763254118445, 0.45828375607521515, 0.46153985407586623, 0.4345373381087693, 0.4279298140665218, 0.42857555926353175, 0.3884656752552621, 0.4154991871934479, 0.4175974351439657, 0.4224376835776039, 0.41714726864415735, 0.405875859777778, 0.3911638635470714, 0.41545869443459005, 0.3839576605301169, 0.3804379748634285, 0.3884555509822459, 0.371046807377816, 0.377188954073057, 0.3715219236535797, 0.37751894656853996, 0.3729826580712893] 
 train_accs 
 [0.49439288476411447, 0.6405645784996133, 0.6755607115235885, 0.7184841453982985, 0.7364655839133798, 0.7536736272235113, 0.7587006960556845, 0.7803557617942769, 0.7704949729311679, 0.7923433874709978, 0.7923433874709978, 0.7971771075019335, 0.8097447795823667, 0.8259860788863109, 0.8302397525135344, 0.8219257540603249, 0.8153518948182522, 0.8317865429234339, 0.8344934261407579, 0.8360402165506574, 0.8431941221964424, 0.8534416086620263, 0.852861562258314, 0.8567285382830627, 0.8495746326372777, 0.8536349574632638, 0.8557617942768755, 0.8557617942768755, 0.8640757927300852, 0.8640757927300852, 0.8609822119102862, 0.8660092807424594, 0.8710363495746327, 0.8714230471771075, 0.882830626450116, 0.8739365815931942, 0.8768368136117557, 0.8752900232018562, 0.8752900232018562, 0.8768368136117557, 0.8834106728538283, 0.8818638824439289, 0.887277648878577, 0.8849574632637278, 0.8826372776488787, 0.8923047177107503, 0.887277648878577, 0.8839907192575407, 0.8876643464810519, 0.8892111368909513] 
 val_accs 
 [0.6040540540540541, 0.716891891891892, 0.789864864864865, 0.7621621621621621, 0.768918918918919, 0.7635135135135136, 0.7858108108108108, 0.822972972972973, 0.8114864864864866, 0.797972972972973, 0.8405405405405406, 0.7993243243243243, 0.8466216216216217, 0.8256756756756757, 0.8567567567567568, 0.8141891891891893, 0.8445945945945946, 0.8317567567567568, 0.8472972972972973, 0.8324324324324325, 0.8412162162162162, 0.8087837837837838, 0.8425675675675676, 0.8587837837837838, 0.8493243243243244, 0.8655405405405406, 0.866891891891892, 0.8628378378378379, 0.8722972972972973, 0.8331081081081082, 0.8621621621621622, 0.852027027027027, 0.8722972972972973, 0.8675675675675676, 0.866891891891892, 0.8527027027027028, 0.8844594594594595, 0.8770270270270271, 0.8878378378378379, 0.8533783783783784, 0.8587837837837838, 0.8831081081081081, 0.870945945945946, 0.8662162162162163, 0.8614864864864865, 0.8716216216216217, 0.8810810810810812, 0.8912162162162163, 0.8682432432432433, 0.8628378378378379] 
 val_losses 
 [1.233040819619153, 1.02440400381346, 0.6589328083637599, 0.7662450341759501, 0.749280434846878, 0.8088145819870202, 0.8430778393874298, 0.6425495157370696, 0.6210941295366029, 0.7268409142623077, 0.5514350852450809, 0.6337258771464631, 0.539635969295695, 0.6328634854909536, 0.5137583826039288, 0.6466629461662189, 0.5713926777646349, 0.6185399216574592, 0.6075601745296169, 0.6426633628639015, 0.5535732770288313, 0.6989123035121608, 0.6142432038848464, 0.4869460231549031, 0.6063483489526285, 0.4765178032823511, 0.5039028180612101, 0.5237788488736024, 0.49407417387575714, 0.6320395637202907, 0.5454850272760047, 0.5607921342591982, 0.5005791132514541, 0.5110535331674524, 0.48923686066189326, 0.6300717740445524, 0.46180590264675386, 0.5240237277907294, 0.4133327106580239, 0.6555849220905755, 0.5440754278688817, 0.47008095431972197, 0.5405513711877772, 0.5731236834783812, 0.529606717341655, 0.5130906059935286, 0.5105153965486868, 0.40991573173653434, 0.5354855666289459, 0.5306550665683037] 
 test_accs 
 [0.86720871925354] 
 test_losses 
 [0.5026313895132484]

 ############################################################


model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter_size = 1024
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4) 
max_iters = 50
BatchSize = 64

train_losses: 
 [1.6157794310340379, 0.6047294022312297, 0.4943028014939788, 0.43130243753428066, 0.38924570451940754, 0.3920412110618538, 0.3481368106967796, 0.3490647836332624, 0.3414087906330017, 0.3161974360752917, 0.30892262167001266, 0.299042118259483, 0.2713056179966377, 0.27112615961302, 0.28786783221149664, 0.28459802442802906, 0.2639521400733042, 0.2674686996769002, 0.25229271852223334, 0.23365731124189226, 0.23689806174374511, 0.2540265411392073, 0.2344615189653907, 0.23444545682741522, 0.2258167676656447, 0.2005632028778855, 0.2349229517572164, 0.22599802949312392, 0.22943018087562625, 0.22550806550673524, 0.20992078414879745, 0.20072804514696133, 0.19418778448536336, 0.22411773509971872, 0.210954352994345, 0.19375865228260938, 0.20877417742237966, 0.20650235385463298, 0.21361476947011085, 0.18731416888932617, 0.20741433462982295, 0.1869805386982864, 0.2153882863027406, 0.1810312320327722, 0.19311497772468308, 0.18934907056016692, 0.19295601474160107, 0.167227318281364, 0.15929120066824204, 0.21130510952614667] 
 train_accs 
 [0.6370843000773395, 0.8234725444702243, 0.8489945862335654, 0.8704563031709204, 0.8826372776488787, 0.8820572312451663, 0.8967517401392112, 0.8965583913379738, 0.895784996133024, 0.9052590873936582, 0.908739365815932, 0.9102861562258314, 0.919953596287703, 0.9240139211136892, 0.912799690641918, 0.9137664346481053, 0.9203402938901779, 0.9168600154679042, 0.9273008507347255, 0.9261407579273009, 0.9284609435421501, 0.9253673627223512, 0.9296210363495747, 0.9292343387470998, 0.9338747099767982, 0.9394818252126838, 0.9290409899458624, 0.9332946635730859, 0.9296210363495747, 0.9323279195668988, 0.9383217324052592, 0.940061871616396, 0.9431554524361949, 0.9332946635730859, 0.9373549883990719, 0.9425754060324827, 0.9383217324052592, 0.9377416860015468, 0.9354215003866977, 0.9443155452436195, 0.9381283836040217, 0.9431554524361949, 0.9363882443928848, 0.9454756380510442, 0.9437354988399073, 0.9392884764114463, 0.9390951276102089, 0.9505027068832174, 0.9506960556844548, 0.9369682907965972] 
 val_accs 
 [0.8925675675675676, 0.9054054054054055, 0.8986486486486487, 0.920945945945946, 0.920945945945946, 0.9222972972972974, 0.9101351351351352, 0.9256756756756758, 0.9202702702702703, 0.9290540540540541, 0.9283783783783784, 0.9162162162162163, 0.9195945945945947, 0.9277027027027027, 0.9243243243243244, 0.9162162162162163, 0.9182432432432432, 0.9182432432432432, 0.9216216216216216, 0.9101351351351352, 0.9081081081081082, 0.9081081081081082, 0.9243243243243244, 0.9108108108108108, 0.9236486486486487, 0.9135135135135135, 0.9195945945945947, 0.9135135135135135, 0.9047297297297298, 0.9175675675675676, 0.918918918918919, 0.9182432432432432, 0.9101351351351352, 0.9243243243243244, 0.914864864864865, 0.9175675675675676, 0.9087837837837839, 0.9270270270270271, 0.9141891891891892, 0.9040540540540541, 0.9047297297297298, 0.9081081081081082, 0.9168918918918919, 0.9135135135135135, 0.9216216216216216, 0.9141891891891892, 0.9108108108108108, 0.914864864864865, 0.9128378378378379, 0.9175675675675676] 
 val_losses 
 [0.40873603917456963, 0.28486358011896545, 0.3212696098596663, 0.25395890595139686, 0.26473051599554115, 0.2537025511264801, 0.2858172395744839, 0.23953360391629708, 0.24357666727658864, 0.22239394461786424, 0.24982474397968601, 0.2722543226706015, 0.27974893068139617, 0.2121231786705352, 0.2722953028976917, 0.29619361887107026, 0.31569216219154567, 0.2729431538968473, 0.2752493988219145, 0.35167032705770956, 0.3123822093815417, 0.31862352200708277, 0.25995858986232734, 0.30043120640959287, 0.2861948070849443, 0.29305894124145443, 0.3063920428624024, 0.31589926883981034, 0.3552580321157301, 0.3134687335117141, 0.2790527812884869, 0.2962703230614598, 0.33207852792095494, 0.2889023996688224, 0.29718811447555954, 0.29357934706416483, 0.36274923053947655, 0.32483135171838706, 0.3244344021017487, 0.3693489148810103, 0.34678824177464923, 0.3074591902462212, 0.3298603845609201, 0.344894306754341, 0.3354473758186843, 0.3294074181567978, 0.332890245237866, 0.31353228656021326, 0.35802715146863784, 0.3386693626667398] 
 test_accs 
 [0.9281842708587646] 
 test_losses 
 [0.22751370096594337]


 ################################################################
model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, output_size),)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
max_iters = 50
BatchSize = 64

train_losses: 
 [1.9726980707945976, 0.6752422844266486, 0.5287171373603331, 0.47264237152174843, 0.4193640919683151, 0.3993542308458873, 0.3887655885295175, 0.3784342304920837, 0.3409862281367102, 0.3313437415847277, 0.3325533824011234, 0.30372474070030503, 0.3553484174878857, 0.29153056625976914, 0.29060857301060766, 0.2672355818545643, 0.2836394191410591, 0.2853782248423253, 0.286242339330778, 0.2575715750755493, 0.27454445960557655, 0.25552304701019607, 0.25795949104674915, 0.24839910007408214, 0.25367774593673376, 0.22573175984856148, 0.24064490978144346, 0.24666504385576446, 0.2380569883653201, 0.2207704113374269, 0.20250422495423778, 0.24124043257957453, 0.22810412643726538, 0.23992904075705904, 0.22193260417137603, 0.23102305517211408, 0.20664371037243506, 0.21522253707385489, 0.20307841929279366, 0.20799177042039346, 0.21765595497037676, 0.20699596385437669, 0.19518982942309016, 0.21107568757209497, 0.20348341525038913, 0.19850098503622451, 0.2168845739114773, 0.1849992236515762, 0.19164669065399864, 0.19087951190694763] 
 train_accs 
 [0.5651585460170148, 0.7983372003093582, 0.8445475638051044, 0.8604021655065739, 0.8749033255993813, 0.8805104408352669, 0.8834106728538283, 0.8859242072699149, 0.8979118329466358, 0.901585460170147, 0.8979118329466358, 0.9083526682134572, 0.8909512761020882, 0.9126063418406807, 0.9112529002320187, 0.9197602474864657, 0.9153132250580047, 0.9112529002320187, 0.9147331786542924, 0.9253673627223512, 0.9187935034802784, 0.9234338747099768, 0.919953596287703, 0.9263341067285383, 0.9245939675174014, 0.9338747099767982, 0.9288476411446249, 0.9251740139211138, 0.9296210363495747, 0.9331013147718484, 0.9410286156225832, 0.9274941995359629, 0.9290409899458624, 0.9273008507347255, 0.9336813611755608, 0.9327146171693736, 0.9385150812064965, 0.9344547563805105, 0.9375483372003094, 0.9358081979891725, 0.9323279195668988, 0.9369682907965972, 0.9425754060324827, 0.941415313225058, 0.940061871616396, 0.9404485692188709, 0.9379350348027843, 0.9404485692188709, 0.9390951276102089, 0.9427687548337201] 
 val_accs 
 [0.8722972972972973, 0.8851351351351352, 0.9, 0.914864864864865, 0.9256756756756758, 0.9182432432432432, 0.9243243243243244, 0.922972972972973, 0.9128378378378379, 0.9155405405405406, 0.914864864864865, 0.9162162162162163, 0.9256756756756758, 0.9155405405405406, 0.9216216216216216, 0.9175675675675676, 0.9108108108108108, 0.9060810810810811, 0.9108108108108108, 0.9222972972972974, 0.918918918918919, 0.918918918918919, 0.920945945945946, 0.9243243243243244, 0.9202702702702703, 0.9108108108108108, 0.9114864864864866, 0.9141891891891892, 0.9135135135135135, 0.9054054054054055, 0.9087837837837839, 0.9067567567567568, 0.9101351351351352, 0.9202702702702703, 0.9135135135135135, 0.9304054054054055, 0.9168918918918919, 0.9067567567567568, 0.9135135135135135, 0.9108108108108108, 0.9175675675675676, 0.9141891891891892, 0.9128378378378379, 0.9128378378378379, 0.9236486486486487, 0.9216216216216216, 0.9195945945945947, 0.918918918918919, 0.9236486486486487, 0.9074324324324324] 
 val_losses 
 [0.46533974473540846, 0.36911477933864334, 0.33090560698025934, 0.26392811971741753, 0.2646135673531004, 0.24876108910586384, 0.25689691933425696, 0.252689346429464, 0.2920515406776119, 0.25872467820708817, 0.2952089643602989, 0.2837108057898444, 0.2649444095186285, 0.30594567034796283, 0.3187677922281059, 0.301389073681187, 0.3221108737426835, 0.30211322569363824, 0.33678958158235295, 0.3031829293213181, 0.2637025638143658, 0.27975217342578074, 0.3021132814723092, 0.30237297480170794, 0.2676522331463324, 0.32787989627922304, 0.31474947421937377, 0.32469418983201725, 0.3188663759747067, 0.36739134867172185, 0.3692963593714946, 0.324046669376863, 0.3380527851549355, 0.29437485063398205, 0.3272566759908522, 0.2967987751638567, 0.35817355304150966, 0.36077660171289905, 0.3525129466934281, 0.33914895532904443, 0.3352994392852525, 0.3301975812460925, 0.38718477096912024, 0.36747620238645656, 0.3170837805883304, 0.3049796523324944, 0.3387200436479337, 0.29931545982489716, 0.2792699279011907, 0.38033916680268137] 
 test_accs 
 [0.9146341681480408] 
 test_losses 
 [0.3281895127399827]



 ##################################################################

model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, output_size),)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-5)
max_iters = 50
BatchSize = 64


 train_losses: 
 [2.570044925668308, 0.8466469892124197, 0.5263877649779294, 0.44187018664788574, 0.39628767130546394, 0.340081508663949, 0.31164336499555667, 0.3284146638683635, 0.2987027290433484, 0.2859644444064401, 0.28073281003630446, 0.2514654052575614, 0.2553073390223495, 0.24932421012064881, 0.22250743796912073, 0.2177110221136105, 0.24228532525890112, 0.21944312489687337, 0.19091582722379916, 0.21723603510801312, 0.1955798743127025, 0.22262740665319256, 0.1992092784623812, 0.19966136709673868, 0.18893225510638534, 0.1968213258007194, 0.1772196157118745, 0.18718377257029584, 0.19042184145088262, 0.17134882738469465, 0.1779907165528819, 0.17030843490790878, 0.1760960074353384, 0.16510566898491247, 0.14872145887870522, 0.16118387397946263, 0.16307517770916938, 0.15311791698829388, 0.16295256791240192, 0.15895087010899164, 0.13832966917628756, 0.16072074960908592, 0.16366988709751065, 0.1512731089842292, 0.1420362155426406, 0.14911357970866507, 0.1448187026305431, 0.14573365138744257, 0.1221049566769775, 0.1554595138892036] 
 train_accs 
 [0.49825986078886314, 0.7946635730858469, 0.8617556071152359, 0.8710363495746327, 0.8837973704563032, 0.8988785769528229, 0.9098994586233565, 0.902938901778809, 0.9102861562258314, 0.9207269914926528, 0.9191802010827533, 0.9267208043310132, 0.9234338747099768, 0.9238205723124517, 0.9344547563805105, 0.9375483372003094, 0.9274941995359629, 0.9383217324052592, 0.9445088940448569, 0.9377416860015468, 0.9439288476411447, 0.9325212683681362, 0.9412219644238207, 0.9406419180201083, 0.9448955916473318, 0.9418020108275329, 0.9464423820572313, 0.9450889404485693, 0.9418020108275329, 0.9491492652745553, 0.9487625676720804, 0.9508894044856923, 0.9460556844547564, 0.9535962877030163, 0.9534029389017789, 0.9532095901005414, 0.9534029389017789, 0.9563031709203403, 0.9512761020881672, 0.9520494972931168, 0.9568832173240527, 0.9491492652745553, 0.9503093580819799, 0.9564965197215778, 0.9590100541376644, 0.9551430781129158, 0.9563031709203403, 0.9559164733178654, 0.9650038669760248, 0.9549497293116783] 
 val_accs 
 [0.8506756756756757, 0.9067567567567568, 0.9304054054054055, 0.9324324324324325, 0.9304054054054055, 0.9398648648648649, 0.9331081081081082, 0.9385135135135135, 0.9405405405405406, 0.9493243243243243, 0.9398648648648649, 0.9317567567567568, 0.9466216216216217, 0.9304054054054055, 0.9310810810810811, 0.9425675675675677, 0.9364864864864866, 0.9432432432432433, 0.9378378378378379, 0.9351351351351351, 0.9324324324324325, 0.9432432432432433, 0.9337837837837838, 0.9398648648648649, 0.9418918918918919, 0.9358108108108109, 0.9398648648648649, 0.925, 0.9351351351351351, 0.9337837837837838, 0.9331081081081082, 0.9324324324324325, 0.9358108108108109, 0.9405405405405406, 0.9304054054054055, 0.9270270270270271, 0.9324324324324325, 0.9358108108108109, 0.9398648648648649, 0.9418918918918919, 0.9364864864864866, 0.9324324324324325, 0.9317567567567568, 0.9358108108108109, 0.9310810810810811, 0.925, 0.9391891891891893, 0.9324324324324325, 0.9270270270270271, 0.9331081081081082] 
 val_losses 
 [0.8123879725868638, 0.32606086054363764, 0.24043296285577723, 0.20974168662686607, 0.21829911132116575, 0.20901427478403659, 0.20935301455492908, 0.2029049500420287, 0.2006657207334364, 0.1830037137946567, 0.19389607261967015, 0.20368582540871324, 0.1851489666345957, 0.21174930076341372, 0.19872080893129915, 0.19236054131006067, 0.21497517308673342, 0.22430880436220685, 0.2107876345112517, 0.21185930226300215, 0.2440388784215257, 0.2136530083578986, 0.22823235719666085, 0.21628394473243404, 0.21243577857275267, 0.24712622045614832, 0.2278502797154156, 0.279444127429176, 0.23757931606189625, 0.24359740212156966, 0.2460450749139528, 0.23517756683600916, 0.24738465958665048, 0.2379418298696495, 0.24881097948228992, 0.2509586088963457, 0.26260585687249094, 0.250603117894482, 0.25051845553758983, 0.23683565131835388, 0.2606919212483902, 0.25262439250946045, 0.24197952256009386, 0.2551900230549477, 0.2695185156878889, 0.2696183438236649, 0.25053630418874123, 0.25896337374642087, 0.27217415093972874, 0.2603588217013591] 
 test_accs 
 [0.922764241695404] 
 test_losses 
 [0.2457249357609891]


data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
for all above, using the data transform from 12/8
################################################3
new data transforms


 data_transforms = {
    'train': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

train_losses: 
 [2.302317376802434, 0.39823315471802584, 0.11824197882220253, 0.0470226598991411, 0.020819253093013447, 0.01600058075639852, 0.0191516711881524, 0.014103304921762481] 
 train_accs 
 [0.6051817478731633, 0.9193735498839908, 0.9769914926527457, 0.9934261407579273, 0.9984532095901006, 0.9978731631863883, 0.9953596287703017, 0.9969064191802012] 
 val_accs 
 [0.8871621621621623, 0.9243243243243244, 0.9283783783783784, 0.9452702702702703, 0.9310810810810811, 0.9391891891891893, 0.9371621621621622] 
 val_losses 
 [0.729988236685057, 0.27536109653679103, 0.21085957014882886, 0.1853127653534348, 0.20067083491264162, 0.2026487769307317, 0.22623365408665425] 
 test_accs 
 [0.9322493672370911] 
 test_losses 
 [0.21932994923617458]

 ######################################################
 #laod data
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, output_size),)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-5)
iter_max =50

train_losses: 
 [2.5774121378524675, 0.7966374866001752, 0.5506550732363312, 0.44210025244043116, 0.40455551485819863, 0.37116445689725025, 0.33944620326887426, 0.3102869536188897, 0.30025211619667, 0.2790300235302063, 0.27813854751343514, 0.2646830443808577, 0.26502851087366625, 0.23514080793241707, 0.25639743848263713, 0.25685672685561584, 0.23310749081798238, 0.23835340999671864, 0.2001590049967504, 0.2200989049484079, 0.21493949686383795, 0.2268804717759983, 0.20042120071224528, 0.19491725528507572, 0.1967651405056963, 0.19885355325189563, 0.19347767307144306, 0.2184838072929102, 0.2092656293006618, 0.19399260935263402, 0.18160555149267923, 0.16997626782247288, 0.17384758023494726, 0.17198850817212002, 0.1891398023978187, 0.17853628929880175, 0.18101847741093086, 0.17318825739488433, 0.15678282942959992, 0.17003761049812374, 0.16043270545833718, 0.16385817036251643, 0.16414843869596513, 0.16617766808652176, 0.1574417078912212, 0.1623667150949058, 0.15463552228121083, 0.16915188794300157, 0.14620859602902717, 0.15412860284779115] 
 train_accs 
 [0.538476411446249, 0.8070378963650425, 0.8480278422273783, 0.8706496519721578, 0.8762567672080434, 0.8915313225058005, 0.8988785769528229, 0.9054524361948957, 0.9098994586233565, 0.9189868522815159, 0.9156999226604795, 0.923047177107502, 0.9143464810518175, 0.9311678267594742, 0.9226604795050272, 0.9220804331013148, 0.9296210363495747, 0.9280742459396752, 0.9412219644238207, 0.932907965970611, 0.9361948955916474, 0.931554524361949, 0.941415313225058, 0.941415313225058, 0.9389017788089714, 0.9427687548337201, 0.9431554524361949, 0.9313611755607115, 0.9383217324052592, 0.9429621036349575, 0.9479891724671308, 0.9489559164733179, 0.9503093580819799, 0.9506960556844548, 0.9437354988399073, 0.9483758700696057, 0.9470224284609436, 0.9497293116782677, 0.9547563805104409, 0.9534029389017789, 0.9535962877030163, 0.9514694508894045, 0.9510827532869297, 0.949922660479505, 0.9524361948955917, 0.9510827532869297, 0.9576566125290024, 0.9508894044856923, 0.9559164733178654, 0.9535962877030163] 
 val_accs 
 [0.8554054054054054, 0.9236486486486487, 0.918918918918919, 0.943918918918919, 0.9398648648648649, 0.9243243243243244, 0.9391891891891893, 0.9418918918918919, 0.9445945945945946, 0.9445945945945946, 0.9371621621621622, 0.9337837837837838, 0.9358108108108109, 0.9358108108108109, 0.9344594594594595, 0.9337837837837838, 0.9398648648648649, 0.9351351351351351, 0.9412162162162163, 0.9351351351351351, 0.9391891891891893, 0.9398648648648649, 0.9493243243243243, 0.9351351351351351, 0.9351351351351351, 0.9398648648648649, 0.9337837837837838, 0.9236486486486487, 0.943918918918919, 0.9385135135135135, 0.9398648648648649, 0.9310810810810811, 0.9344594594594595, 0.9168918918918919, 0.9324324324324325, 0.9391891891891893, 0.9398648648648649, 0.9297297297297298, 0.9331081081081082, 0.9331081081081082, 0.9405405405405406, 0.9391891891891893, 0.9337837837837838, 0.9310810810810811, 0.9391891891891893, 0.9297297297297298, 0.9304054054054055, 0.9270270270270271, 0.9304054054054055, 0.9378378378378379] 
 val_losses 
 [0.801768450801437, 0.30700458417067655, 0.2519979597748937, 0.18987060108700315, 0.1967492168014114, 0.2288286968260198, 0.21142575293779373, 0.1897580007644924, 0.18646639581467656, 0.18712218589073903, 0.1965265670036142, 0.2188217842901075, 0.21016352253185736, 0.18802019502665546, 0.23846549792466937, 0.19800863040460123, 0.19162151789343035, 0.2374459668591216, 0.205526253550842, 0.2198749330970836, 0.20497740885695895, 0.2007646947293668, 0.17315539951260026, 0.21530624700559153, 0.23816940663004849, 0.22733637057244777, 0.2180809281741244, 0.24639568566973952, 0.19853811286691878, 0.2389995127110868, 0.2070102822236918, 0.23191657724186174, 0.22082682574117507, 0.3366894901377728, 0.24036923317691763, 0.21748044668017208, 0.2144928990989118, 0.2657418969005497, 0.22908893316178708, 0.26406251669490105, 0.23986511043606426, 0.22260263811897588, 0.2560409776262335, 0.229288154115548, 0.2532204580971518, 0.2584766674786806, 0.249934204335551, 0.25520699716903067, 0.26293629052076567, 0.21827078952030846] 
 test_accs 
 [0.9295393228530884, 0.9295393228530884] 
 test_losses 
 [0.22150167685537156, 0.2215040452515853]

 #######################################################
 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, output_size),)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-5)

#laod data
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter = 50

train_losses: 
 [1.6944130347942254, 0.7097085434064695, 0.547601455832671, 0.47944158011412125, 0.4219169304616121, 0.39572026525830817, 0.35867257611012143, 0.34363276063704434, 0.3235100996835418, 0.31639414684586253, 0.2791785757991572, 0.2803477037349415, 0.259305994591783, 0.27036912643623645, 0.2586667142860298, 0.22759186663741948, 0.23552422067589845, 0.2470346400881588, 0.2331872441836871, 0.21258182366135872, 0.23750403505005951, 0.214743693289329, 0.21595329294025853, 0.20134154056636105, 0.20404998713791694, 0.20188511602655457, 0.19567801285324776, 0.19488476592491324, 0.20092883295821112, 0.17727442366940424, 0.19359830874670225, 0.15364804624220427, 0.18017650571092098, 0.1662305587670735, 0.19131055260502083, 0.17993438062355302, 0.1941883208695439, 0.15262468224888334, 0.16346470458463283, 0.17440515644819535, 0.1722134321305702, 0.16051816906310382, 0.16240032454585254, 0.16248859340081542, 0.16724352629629108, 0.14910263974401072, 0.15264229322023753, 0.1576557460904398, 0.1474337218543954, 0.1518852757398048] 
 train_accs 
 [0.6960556844547564, 0.8517014694508894, 0.8758700696055685, 0.8822505800464038, 0.8969450889404487, 0.9000386697602475, 0.9079659706109823, 0.9110595514307812, 0.919953596287703, 0.915893271461717, 0.9294276875483373, 0.9259474091260634, 0.9321345707656613, 0.9278808971384378, 0.932907965970611, 0.9402552204176334, 0.9352281515854602, 0.9334880123743233, 0.9389017788089714, 0.9416086620262955, 0.9354215003866977, 0.9410286156225832, 0.9394818252126838, 0.945862335653519, 0.9443155452436195, 0.9435421500386698, 0.947215777262181, 0.9462490332559939, 0.9464423820572313, 0.9501160092807425, 0.9450889404485693, 0.9576566125290024, 0.9541763341067286, 0.9551430781129158, 0.9476024748646559, 0.9495359628770302, 0.9481825212683682, 0.9593967517401393, 0.9564965197215778, 0.9476024748646559, 0.9526295436968292, 0.9559164733178654, 0.9551430781129158, 0.9528228924980665, 0.9508894044856923, 0.9576566125290024, 0.9592034029389018, 0.9559164733178654, 0.9582366589327147, 0.9578499613302398] 
 val_accs 
 [0.9418918918918919, 0.943918918918919, 0.9385135135135135, 0.9493243243243243, 0.9472972972972974, 0.9452702702702703, 0.9432432432432433, 0.9506756756756757, 0.9547297297297298, 0.945945945945946, 0.9398648648648649, 0.945945945945946, 0.9412162162162163, 0.9445945945945946, 0.945945945945946, 0.947972972972973, 0.9412162162162163, 0.9337837837837838, 0.9412162162162163, 0.9385135135135135, 0.9391891891891893, 0.9445945945945946, 0.9398648648648649, 0.9378378378378379, 0.9344594594594595, 0.9344594594594595, 0.9364864864864866, 0.9344594594594595, 0.9398648648648649, 0.9344594594594595, 0.9371621621621622, 0.9371621621621622, 0.9317567567567568, 0.9371621621621622, 0.9385135135135135, 0.9331081081081082, 0.9331081081081082, 0.9317567567567568, 0.9317567567567568, 0.9378378378378379, 0.9358108108108109, 0.9398648648648649, 0.9337837837837838, 0.9270270270270271, 0.9222972972972974, 0.9317567567567568, 0.9364864864864866, 0.9317567567567568, 0.9331081081081082, 0.9317567567567568] 
 val_losses 
 [0.5257103642901859, 0.31102543610173305, 0.2717784354010144, 0.2230913352321934, 0.21055533680561425, 0.2018932319573454, 0.19640521793752103, 0.1942433512694127, 0.19454281185124372, 0.1800292003396395, 0.21572201856084772, 0.17856172367527678, 0.1854654888144216, 0.21941701592625798, 0.19213262543686338, 0.18101136789128586, 0.19692213712511836, 0.22395364940166473, 0.19973210499093338, 0.20456899948216772, 0.19489588894554086, 0.19454212672001606, 0.20273027967762303, 0.20999745553409732, 0.22807113866548281, 0.22409014974695604, 0.23217390237023702, 0.21362332669464318, 0.19775464043423935, 0.22903279201001733, 0.22323494279706801, 0.22152846491820102, 0.2373048177442035, 0.23711496933891968, 0.22281132895700834, 0.23539504586039361, 0.22674860003832223, 0.2505904874286136, 0.219467008597142, 0.2147712402448461, 0.21224989595042693, 0.21294007077813148, 0.2327671281389288, 0.2461872472956374, 0.25324959095592636, 0.23215947372687828, 0.21149363905015225, 0.23936645581915572, 0.23314965407590607, 0.23131459498828327] 
 test_accs 
 [0.9214092493057251] 
 test_losses 
 [0.24443329898968622]

 ##############################################################

  model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, output_size),)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)

#laod data
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter = 50

train_losses: 
 [1.3651106606503374, 0.6895854818387632, 0.5414889219742087, 0.4799434683715661, 0.43593631639834624, 0.40033371482629326, 0.3921107484081044, 0.34895586559501435, 0.35728628722531613, 0.34871381447468264, 0.32574792394136515, 0.325896016521594, 0.30224583677699746, 0.30168339727649557, 0.2909501138944913, 0.2998537709108177, 0.29139840884072227, 0.27016211354677194, 0.27394673940477127, 0.28201305623074785, 0.2504264430905716, 0.2593019015724034, 0.30134057023685656, 0.2396372604397776, 0.23976457121869157, 0.2467561695733369, 0.22967361311348297, 0.23336271359675262, 0.23534583812615525, 0.23920800283908475, 0.24453853659637198, 0.22393267576950793, 0.23375742355244897, 0.22612122842164714, 0.21954022447037677, 0.21751247229427675, 0.2351722675854627, 0.2076485708574869, 0.20401639502844143, 0.20902099440195537, 0.23162601080313266, 0.20277192375614767, 0.20006971290566988, 0.17294640835642539, 0.2154505277615781, 0.20267655274615395, 0.2018727452968869, 0.21300468706199574, 0.19581011938592396, 0.2033333491536876] 
 train_accs 
 [0.7208043310131478, 0.831399845320959, 0.8559551430781129, 0.8749033255993813, 0.8797370456303172, 0.8928847641144625, 0.8897911832946637, 0.8981051817478732, 0.8994586233565353, 0.9021655065738593, 0.9089327146171694, 0.9106728538283063, 0.915893271461717, 0.9129930394431555, 0.9203402938901779, 0.9170533642691415, 0.9162799690641918, 0.9242072699149265, 0.9242072699149265, 0.9218870843000774, 0.9267208043310132, 0.9269141531322507, 0.9137664346481053, 0.9313611755607115, 0.9313611755607115, 0.9346481051817479, 0.9327146171693736, 0.9346481051817479, 0.9317478731631864, 0.9307811291569993, 0.9265274555297758, 0.9325212683681362, 0.9317478731631864, 0.9371616395978345, 0.9383217324052592, 0.9373549883990719, 0.9327146171693736, 0.9425754060324827, 0.9402552204176334, 0.9367749419953597, 0.9354215003866977, 0.9392884764114463, 0.9418020108275329, 0.9462490332559939, 0.9408352668213458, 0.9421887084300078, 0.9402552204176334, 0.9385150812064965, 0.9445088940448569, 0.9408352668213458] 
 val_accs 
 [0.9114864864864866, 0.9155405405405406, 0.9277027027027027, 0.9236486486486487, 0.9304054054054055, 0.9297297297297298, 0.9263513513513514, 0.9236486486486487, 0.9277027027027027, 0.9277027027027027, 0.9202702702702703, 0.9283783783783784, 0.9216216216216216, 0.9283783783783784, 0.9351351351351351, 0.9378378378378379, 0.9324324324324325, 0.9331081081081082, 0.9310810810810811, 0.9263513513513514, 0.9243243243243244, 0.9263513513513514, 0.9304054054054055, 0.9310810810810811, 0.9216216216216216, 0.9324324324324325, 0.9331081081081082, 0.9256756756756758, 0.9216216216216216, 0.9277027027027027, 0.9283783783783784, 0.920945945945946, 0.9263513513513514, 0.9371621621621622, 0.9135135135135135, 0.9263513513513514, 0.9222972972972974, 0.925, 0.9283783783783784, 0.9283783783783784, 0.9378378378378379, 0.9337837837837838, 0.9114864864864866, 0.9297297297297298, 0.9114864864864866, 0.9310810810810811, 0.9128378378378379, 0.9202702702702703, 0.9331081081081082, 0.9283783783783784] 
 val_losses 
 [0.4252276752446149, 0.3188413359023429, 0.2654132488611582, 0.26953365641671256, 0.25551820719564283, 0.24865785450548739, 0.2588809779366931, 0.25395943409687766, 0.24158484037663486, 0.2761064909599923, 0.2772598978635427, 0.23781844737964708, 0.2725062950438744, 0.2337765307039828, 0.2570917844772339, 0.22537407033346796, 0.226397136900876, 0.22404033944413468, 0.23911431560645233, 0.26271116765769753, 0.25195276648611636, 0.2730683054472949, 0.23127264990597157, 0.23441966063267475, 0.2679020241909736, 0.2503766011547398, 0.22753573972417193, 0.27148805594675846, 0.26014493328292626, 0.2481111540987685, 0.24414511339084521, 0.2918016940355301, 0.2711193389385133, 0.24782025377089914, 0.2713785599212389, 0.26566367568196475, 0.2746080093438158, 0.2555303583274017, 0.25635328035096866, 0.2497390460323643, 0.24656671201055114, 0.245600454358233, 0.29756948496844315, 0.2488701880380914, 0.3446437931544072, 0.2513970709330327, 0.3126631731519828, 0.2953633638652595, 0.2478796931134688, 0.2457536719940804] 
 test_accs 
 [0.924119234085083] 
 test_losses 
 [0.2408573423540043]


 ##################################################################

   model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, output_size),)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)

#laod data
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max = 50

train_losses: 
 [1.6591255358274095, 0.8254461643406337, 0.6909654869741925, 0.6174945013060278, 0.5565259083702134, 0.5167805150739001, 0.4799637303781989, 0.42926018337639194, 0.4572069598830032, 0.4469828501931476, 0.40421974398512667, 0.39202656417693266, 0.3752898955105444, 0.3738522431182935, 0.37334521897338846, 0.3632131388089681, 0.354146613333913, 0.34677583009165935, 0.34572727725843266, 0.3267353772771331, 0.3100150942871576, 0.3136414289935467, 0.30001422732907124, 0.30111226126009977, 0.30832287738328745, 0.2884897071081635, 0.30177180200515563, 0.29753528769313137, 0.27430366781775745, 0.2782065829309676, 0.26714411569213276, 0.2609098651730913, 0.2731899431253346, 0.26197506672913773, 0.26462437347303686, 0.2591772511981756, 0.2792538595194975, 0.2649276048198561, 0.24906806005863652, 0.23952827182557357, 0.2672454975689462, 0.2493163611270251, 0.2144625744935808, 0.2237859784819226, 0.2662714369427946, 0.23029639671591945, 0.21330928786355954, 0.23764550563146786, 0.22981828471900692, 0.2043836103422367] 
 train_accs 
 [0.6384377416860015, 0.7940835266821347, 0.8116782675947409, 0.8310131477184842, 0.8433874709976799, 0.8569218870843002, 0.8636890951276103, 0.8799303944315545, 0.869876256767208, 0.8708430007733953, 0.8892111368909513, 0.8849574632637278, 0.8926914153132252, 0.8934648105181748, 0.8926914153132252, 0.8963650425367363, 0.895784996133024, 0.8990719257540604, 0.8994586233565353, 0.9052590873936582, 0.9083526682134572, 0.9079659706109823, 0.9089327146171694, 0.910092807424594, 0.9089327146171694, 0.915893271461717, 0.9126063418406807, 0.9097061098221192, 0.9191802010827533, 0.9205336426914154, 0.9187935034802784, 0.923047177107502, 0.9180201082753288, 0.9213070378963651, 0.9203402938901779, 0.9224671307037897, 0.918600154679041, 0.9226604795050272, 0.9265274555297758, 0.9288476411446249, 0.9220804331013148, 0.9265274555297758, 0.9396751740139212, 0.9305877803557618, 0.9218870843000774, 0.9375483372003094, 0.9365815931941223, 0.9276875483372004, 0.9325212683681362, 0.9433488012374324] 
 val_accs 
 [0.8885135135135136, 0.9074324324324324, 0.9182432432432432, 0.9222972972972974, 0.9101351351351352, 0.9304054054054055, 0.9324324324324325, 0.9182432432432432, 0.9074324324324324, 0.9216216216216216, 0.9162162162162163, 0.9222972972972974, 0.9060810810810811, 0.9222972972972974, 0.9033783783783784, 0.9263513513513514, 0.9108108108108108, 0.9141891891891892, 0.9108108108108108, 0.9054054054054055, 0.9094594594594595, 0.9067567567567568, 0.9155405405405406, 0.9202702702702703, 0.9182432432432432, 0.9087837837837839, 0.9074324324324324, 0.9202702702702703, 0.9141891891891892, 0.9060810810810811, 0.9101351351351352, 0.9128378378378379, 0.9202702702702703, 0.9027027027027028, 0.9162162162162163, 0.9114864864864866, 0.9094594594594595, 0.9074324324324324, 0.9128378378378379, 0.920945945945946, 0.9094594594594595, 0.9074324324324324, 0.9182432432432432, 0.9054054054054055, 0.9101351351351352, 0.914864864864865, 0.9108108108108108, 0.9114864864864866, 0.9168918918918919, 0.9243243243243244] 
 val_losses 
 [0.6175931766226485, 0.37797018225128587, 0.3318213243742247, 0.2852012006012169, 0.320825267160261, 0.24605564120653514, 0.2438991633621422, 0.28211130958956643, 0.318945963076643, 0.2627998555834229, 0.26553170068843945, 0.2549279642266196, 0.30754129685260156, 0.2655774093409245, 0.30768346202534597, 0.23801705192875217, 0.29383692189648347, 0.2753739087162791, 0.2930424074868898, 0.322488668883169, 0.2821254565909102, 0.3101112122471268, 0.279068467323039, 0.2705326732852169, 0.2706240542031623, 0.3182427641809792, 0.308417153116819, 0.2706403679138905, 0.2945254366039424, 0.31802196341591915, 0.3139061570293396, 0.31358076720624356, 0.2773998621851206, 0.33794070385597846, 0.278809019117742, 0.33088017621555843, 0.31171009379464226, 0.3198379774754112, 0.3238596800311997, 0.2754768302412452, 0.34290338964075656, 0.33185806095197395, 0.30486663869909336, 0.3553198218125397, 0.31919705537525384, 0.29463274704443443, 0.3143365839546597, 0.3158570143822077, 0.2906185626983643, 0.2879975646205649] 
 test_accs 
 [0.9078590869903564] 
 test_losses 
 [0.29148168470155256]

 #######################################################################

 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, output_size),)
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max=50

train_losses: 
 [1.6795637212976042, 0.7944920867888944, 0.66658884545029, 0.6034829856716932, 0.5534325813657077, 0.5281168842905728, 0.4913907155267785, 0.45480107161672373, 0.43094890143460113, 0.42553480364791385, 0.3602001750690478, 0.3249291469446007, 0.30113460205362824, 0.30225365856130826, 0.27941989144980217, 0.2692704593268643, 0.25930527956653543, 0.2599711376894193, 0.24242255126240636, 0.25439910908724483, 0.22712426580206332, 0.21429922459942374, 0.19830999711826616, 0.20826556868361396, 0.19176792402370715, 0.18713470152525227, 0.18812220000243426, 0.1890525749646133, 0.1774172386916589, 0.18273300841761853, 0.16615135366153275, 0.16566497108222714, 0.16645682438320644, 0.1896143449154918, 0.14957133787183546, 0.15500417816159529, 0.16035062951674686, 0.1546226073307117, 0.1477238666453476, 0.15903283320280903, 0.150663274842367, 0.13185755697591123, 0.13765963935059167, 0.1566648409404408, 0.12895020069835358, 0.13827095032660242, 0.12756291363166453, 0.14158877947029916, 0.1356379751084345, 0.12953356800389124] 
 train_accs 
 [0.6221964423820573, 0.8018174787316319, 0.8180587780355763, 0.8333333333333334, 0.8505413766434649, 0.8530549110595514, 0.8590487238979119, 0.8708430007733953, 0.8797370456303172, 0.8764501160092808, 0.8969450889404487, 0.9069992266047952, 0.9153132250580047, 0.9143464810518175, 0.9195668986852282, 0.9245939675174014, 0.9265274555297758, 0.9276875483372004, 0.9286542923433875, 0.9296210363495747, 0.9360015467904099, 0.9410286156225832, 0.9433488012374324, 0.9437354988399073, 0.9470224284609436, 0.9476024748646559, 0.945862335653519, 0.9476024748646559, 0.9512761020881672, 0.9516627996906419, 0.953016241299304, 0.9545630317092034, 0.9522428460943543, 0.9437354988399073, 0.9613302397525136, 0.955723124516628, 0.9568832173240527, 0.9563031709203403, 0.9611368909512762, 0.9586233565351895, 0.9564965197215778, 0.9648105181747874, 0.9622969837587008, 0.9574632637277649, 0.9651972157772623, 0.9603634957463264, 0.9648105181747874, 0.9609435421500387, 0.9651972157772623, 0.9640371229698377] 
 val_accs 
 [0.9013513513513514, 0.9283783783783784, 0.9182432432432432, 0.9155405405405406, 0.920945945945946, 0.9121621621621622, 0.8986486486486487, 0.8925675675675676, 0.918918918918919, 0.9256756756756758, 0.9337837837837838, 0.9398648648648649, 0.9398648648648649, 0.9412162162162163, 0.9432432432432433, 0.9445945945945946, 0.9432432432432433, 0.9371621621621622, 0.9344594594594595, 0.9358108108108109, 0.943918918918919, 0.9412162162162163, 0.9452702702702703, 0.9412162162162163, 0.947972972972973, 0.945945945945946, 0.9445945945945946, 0.9445945945945946, 0.9486486486486487, 0.9452702702702703, 0.945945945945946, 0.9378378378378379, 0.9466216216216217, 0.9486486486486487, 0.9466216216216217, 0.9472972972972974, 0.945945945945946, 0.945945945945946, 0.947972972972973, 0.943918918918919, 0.9445945945945946, 0.9452702702702703, 0.9472972972972974, 0.9425675675675677, 0.9432432432432433, 0.9452702702702703, 0.9432432432432433, 0.9425675675675677, 0.9418918918918919, 0.943918918918919] 
 val_losses 
 [0.5267032103764044, 0.31168462666305335, 0.2995467266520938, 0.3192720952871683, 0.27968975772728794, 0.2887839914576427, 0.3101392787856025, 0.33567921454842026, 0.2740916294624677, 0.2522295442384643, 0.2251065259648336, 0.19741315285901764, 0.19122880600594186, 0.18934018466923688, 0.1926243376087498, 0.1908121616453738, 0.19868138794963425, 0.21381390578037984, 0.22369876773776234, 0.22138025297506436, 0.21017949798622648, 0.20554201418684948, 0.2011851041703611, 0.20741070773754572, 0.19318865566841653, 0.2012481185028682, 0.1981931946768954, 0.19415730221851452, 0.19724722757331423, 0.1918197970157741, 0.19301761984825133, 0.19918327460417876, 0.1928708870719011, 0.19044252336025239, 0.1960409906264898, 0.1923169313300703, 0.19515540925534192, 0.20146731082853434, 0.1952301991952432, 0.1906160481878229, 0.19124415617536855, 0.1902242805506732, 0.19135198807092133, 0.1937634807583448, 0.19345135428011417, 0.1927954259555082, 0.20084387829174866, 0.19385010741046957, 0.19337546181034398, 0.19536366389208548] 
 test_accs 
 [0.9268292784690857] 
 test_losses 
 [0.22584112509479368]

 ######################################################

 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
inter3_size = 256
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, inter3_size),
                               nn.BatchNorm1d(inter3_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter3_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max=50

train_losses: 
 [2.0510222334688426, 1.078022575894715, 0.8608144281081976, 0.7222911360553319, 0.6836619942297054, 0.6214443442900791, 0.5967547606564453, 0.5379164605203379, 0.5342340678414539, 0.4842200093230626, 0.42813371143779916, 0.37697450050252956, 0.34498311269218757, 0.31672177940307433, 0.3275600480000731, 0.3268058046479605, 0.2941441675626485, 0.30640956427547605, 0.29018849996476787, 0.27219925346018636, 0.2510702233165157, 0.25501375249532976, 0.24220628025729068, 0.23732873396364554, 0.22879858324210586, 0.21779149641662443, 0.2333044960852842, 0.19559996997489545, 0.2069837642979087, 0.19680896898110709, 0.2038328341523161, 0.19396082499141576, 0.19739552994085113, 0.1836648799957274, 0.18550220693116581, 0.1707588529296375, 0.17933702286785183, 0.18210011819767932, 0.1753320041683784, 0.16406368918872488, 0.1560324796598638, 0.169580472110319, 0.16538246256016248, 0.16472153040621507, 0.16154319916874146, 0.15018239201313752, 0.15140918614047494, 0.15314722418416313, 0.14217623672970303, 0.14247018959710328] 
 train_accs 
 [0.5846867749419954, 0.7807424593967518, 0.8031709203402939, 0.8306264501160093, 0.828692962103635, 0.8441608662026295, 0.8491879350348028, 0.8636890951276103, 0.8575019334880124, 0.8689095127610209, 0.8832173240525909, 0.8973317865429234, 0.9126063418406807, 0.915893271461717, 0.912799690641918, 0.9122196442382058, 0.9213070378963651, 0.918600154679041, 0.9201469450889405, 0.9280742459396752, 0.9406419180201083, 0.930201082753287, 0.9354215003866977, 0.9371616395978345, 0.9398685228151586, 0.9408352668213458, 0.9381283836040217, 0.948569218870843, 0.9443155452436195, 0.9508894044856923, 0.9476024748646559, 0.9520494972931168, 0.9468290796597062, 0.9526295436968292, 0.9526295436968292, 0.9563031709203403, 0.9518561484918794, 0.9510827532869297, 0.9551430781129158, 0.95707656612529, 0.9609435421500387, 0.9561098221191029, 0.9584300077339521, 0.9572699149265275, 0.9563031709203403, 0.9607501933488013, 0.9586233565351895, 0.9599767981438515, 0.9640371229698377, 0.9607501933488013] 
 val_accs 
 [0.9020270270270271, 0.9135135135135135, 0.918918918918919, 0.9027027027027028, 0.914864864864865, 0.9074324324324324, 0.9054054054054055, 0.9128378378378379, 0.9094594594594595, 0.9270270270270271, 0.9331081081081082, 0.9277027027027027, 0.9324324324324325, 0.9317567567567568, 0.9385135135135135, 0.9358108108108109, 0.9317567567567568, 0.9351351351351351, 0.9277027027027027, 0.922972972972973, 0.9378378378378379, 0.9425675675675677, 0.9432432432432433, 0.9418918918918919, 0.9364864864864866, 0.9364864864864866, 0.9358108108108109, 0.9371621621621622, 0.9405405405405406, 0.9310810810810811, 0.9371621621621622, 0.9452702702702703, 0.9425675675675677, 0.9412162162162163, 0.9432432432432433, 0.9425675675675677, 0.9432432432432433, 0.9432432432432433, 0.9371621621621622, 0.9425675675675677, 0.9412162162162163, 0.9412162162162163, 0.9398648648648649, 0.9412162162162163, 0.9385135135135135, 0.9425675675675677, 0.9425675675675677, 0.9412162162162163, 0.9418918918918919, 0.9425675675675677] 
 val_losses 
 [0.7542453164989884, 0.5462935776323885, 0.4201670111836614, 0.4254385410128413, 0.36724909109038273, 0.3654133790248149, 0.3442587449743941, 0.3250010454976881, 0.3291492054591308, 0.28104759970226806, 0.2594722125981305, 0.25752675766880445, 0.2436150251812226, 0.24374663604272379, 0.2278280119034084, 0.24348151554932465, 0.25946459705765185, 0.23729956834702878, 0.25931585282087327, 0.26248555511638927, 0.21985707349471142, 0.2147318898826032, 0.2152737403238142, 0.2174660054413048, 0.23229671861674334, 0.22407867074818225, 0.23107589386604926, 0.23601880705839878, 0.22299721815900223, 0.23027781022561564, 0.2240030836918064, 0.210162616662077, 0.209955111568844, 0.21233401169648042, 0.21191132745227298, 0.21670305970552806, 0.21121867069521466, 0.2168557639460306, 0.2244780421257019, 0.20919873142564618, 0.21193874784418054, 0.2077156176790595, 0.20833091510308754, 0.2124550424314834, 0.21748557316290365, 0.21103922954785662, 0.21328767248102137, 0.2099502135772963, 0.21357020966809342, 0.20576452260484568] 
 test_accs 
 [0.9430894255638123] 
 test_losses 
 [0.21328431743431867]

 #############################################################
 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
inter3_size = 256
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, inter3_size),
                               nn.BatchNorm1d(inter3_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter3_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.4)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max=40

train_losses: 
 [2.0427210660102473, 1.0685763762887834, 0.8428143085386065, 0.7449804983762283, 0.6496563196090055, 0.6150031081485084, 0.5970901285873673, 0.5338459257137287, 0.5240481269285832, 0.5113713191814968, 0.43009345243812436, 0.35413728902161073, 0.3452330395083785, 0.3214663135295493, 0.33604664324976546, 0.2968990139415443, 0.2985385557361471, 0.29074367804759615, 0.297354584826302, 0.26359559062001137, 0.2652461161492688, 0.24650463201422518, 0.228148804227004, 0.23102494325180525, 0.23028608308406368, 0.22648038404539217, 0.22660199105048123, 0.21039728348972442, 0.20686878553214963, 0.22169825388586806, 0.19473823600744702, 0.20922981132303017, 0.195021726715408, 0.1791154984716104, 0.1838709064121866, 0.17938794584027207, 0.18333404088840868, 0.1814563391472329, 0.19254443462007467, 0.18780879331759862] 
 train_accs 
 [0.5901005413766435, 0.7892498066511988, 0.8116782675947409, 0.8190255220417634, 0.83584686774942, 0.8484145398298532, 0.8451276102088168, 0.8652358855375097, 0.8561484918793504, 0.8638824439288477, 0.884184068058778, 0.9054524361948957, 0.9050657385924208, 0.915893271461717, 0.911446249033256, 0.9195668986852282, 0.9218870843000774, 0.9236272235112143, 0.9205336426914154, 0.9311678267594742, 0.9296210363495747, 0.9354215003866977, 0.9389017788089714, 0.9402552204176334, 0.9410286156225832, 0.9373549883990719, 0.9392884764114463, 0.9464423820572313, 0.9497293116782677, 0.941415313225058, 0.9493426140757928, 0.9439288476411447, 0.9481825212683682, 0.9549497293116783, 0.954369682907966, 0.9547563805104409, 0.9510827532869297, 0.9501160092807425, 0.9474091260634184, 0.9508894044856923] 
 val_accs 
 [0.9087837837837839, 0.9, 0.914864864864865, 0.9135135135135135, 0.9141891891891892, 0.9087837837837839, 0.9108108108108108, 0.9087837837837839, 0.9114864864864866, 0.9027027027027028, 0.9297297297297298, 0.9358108108108109, 0.9452702702702703, 0.9425675675675677, 0.9385135135135135, 0.9398648648648649, 0.9378378378378379, 0.9378378378378379, 0.9412162162162163, 0.9324324324324325, 0.9405405405405406, 0.9391891891891893, 0.9432432432432433, 0.9391891891891893, 0.9398648648648649, 0.9418918918918919, 0.9418918918918919, 0.945945945945946, 0.945945945945946, 0.9432432432432433, 0.9398648648648649, 0.9412162162162163, 0.9418918918918919, 0.9371621621621622, 0.9445945945945946, 0.9425675675675677, 0.943918918918919, 0.9452702702702703, 0.9425675675675677, 0.943918918918919] 
 val_losses 
 [0.8666955548363763, 0.561861996392946, 0.41800874874398514, 0.3774683111422771, 0.38103243756938626, 0.3591615560892466, 0.3240572457377975, 0.3198260363694784, 0.3267728626728058, 0.34844060228080365, 0.23555397959174337, 0.230369611507332, 0.2145351992265598, 0.21509281429084573, 0.22759240843557021, 0.23403473315206733, 0.23048351463433858, 0.23133394540967167, 0.22419710368723483, 0.24468493719358703, 0.22097997870799657, 0.207133390774598, 0.2019329928365108, 0.20884183927162273, 0.2136325670255197, 0.2072145004530211, 0.20504377669579274, 0.20386732172321628, 0.20951122734192254, 0.20682255698216928, 0.2075710737624684, 0.20967352299674138, 0.21044137373163893, 0.21161936964537648, 0.20917180949771727, 0.2104168709468197, 0.20677812436746584, 0.21272889246811738, 0.20443988397113375, 0.20817786406826327] 
 test_accs 
 [0.9308943152427673] 
 test_losses 
 [0.24699833439940683]
 #############################333############

  model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
inter3_size = 256
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter2_size, inter3_size),
                               nn.BatchNorm1d(inter3_size), 
                               nn.ReLU(inplace=True),
                               nn.Linear(inter3_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max=40

train_losses: 
 [2.047416755052288, 1.074341498966468, 0.8482111438889883, 0.7477384877131138, 0.6632304100084931, 0.6179377463374688, 0.574222138152967, 0.5528039557935651, 0.5215009373467926, 0.4857644368674713, 0.4263074069362413, 0.37032001712759244, 0.37304049907778, 0.34153259116277523, 0.3314069870914126, 0.3227532987021146, 0.2929322661490562, 0.2990080710653178, 0.3130591074948337, 0.2822958057183032, 0.2974941697308746, 0.2697538636907163, 0.2722830482559064, 0.2800944086800964, 0.2677817348583853, 0.2694628286735088, 0.2671381753033109] 
 train_accs 
 [0.5864269141531323, 0.7867362722351122, 0.8139984532095902, 0.8246326372776489, 0.8337200309358083, 0.8422273781902553, 0.8497679814385152, 0.8567285382830627, 0.8590487238979119, 0.8633023975251354, 0.8861175560711524, 0.9062258313998454, 0.9021655065738593, 0.9145398298530549, 0.9176334106728539, 0.9162799690641918, 0.9234338747099768, 0.9234338747099768, 0.9191802010827533, 0.9282675947409127, 0.9226604795050272, 0.9309744779582367, 0.9325212683681362, 0.9282675947409127, 0.9331013147718484, 0.9336813611755608, 0.9319412219644239] 
 val_accs 
 [0.8851351351351352, 0.9074324324324324, 0.8898648648648649, 0.9067567567567568, 0.9040540540540541, 0.9114864864864866, 0.9168918918918919, 0.9101351351351352, 0.9141891891891892, 0.9081081081081082, 0.9398648648648649, 0.9391891891891893, 0.9452702702702703, 0.9405405405405406, 0.9398648648648649, 0.9412162162162163, 0.9378378378378379, 0.9378378378378379, 0.9351351351351351, 0.9358108108108109, 0.9378378378378379, 0.9398648648648649, 0.9358108108108109, 0.9378378378378379, 0.9405405405405406, 0.9364864864864866, 0.9398648648648649] 
 val_losses 
 [0.8503385775798076, 0.5575093262904399, 0.4893882811069489, 0.39245441862054775, 0.38044590982230936, 0.3526052031968091, 0.3105656829234716, 0.3238247854484094, 0.30513232440964594, 0.3524863159334337, 0.23719817577181634, 0.2320575028255179, 0.22749878941355525, 0.22566758788920738, 0.22622873940177865, 0.22693177799920777, 0.22505425440298543, 0.22290448526272902, 0.2269038540285987, 0.22436671212718293, 0.22721725380098498, 0.22225162241909954, 0.22332846683424873, 0.22172047479732618, 0.22362588354059168, 0.22453160414824613, 0.22158468003208573] 
 test_accs 
 [0.93360435962677] 
 test_losses 
 [0.23069189981554905]

 ##########################################################

 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
inter3_size = 256
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Dropout(0.1),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Dropout(0.1),
                               nn.Linear(inter2_size, inter3_size),
                               nn.BatchNorm1d(inter3_size), 
                               nn.ReLU(inplace=True),
                               nn.Dropout(0.1),
                               nn.Linear(inter3_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max=40

train_losses: 
 [2.2739561419107153, 1.2021273218746436, 0.9206821580128621, 0.7857487422038858, 0.7058334635701736, 0.6521508099031559, 0.600659907993566, 0.5900443855036347, 0.5509441110945817, 0.5186334749293345, 0.45024957766573465, 0.3936377388971864, 0.3856325350984159, 0.34578833756111244, 0.3518535908994431, 0.3431602849784233, 0.3345998581628512, 0.3166959088436873, 0.30723318896686397, 0.2993765397765151, 0.27670148422989105, 0.2544298086946359, 0.2443740299203464, 0.2537743671864202, 0.2527980895025824, 0.2366282763125264, 0.24163224405774014, 0.2388780900700002, 0.22315185152322675, 0.2295461355810099, 0.22857393308240873, 0.2058102056580003, 0.2053695702313086, 0.20994186420958816, 0.18223772711377687, 0.17180724193076247, 0.2080686020002933, 0.1914011286679664, 0.19012631292686108, 0.19329939008173977] 
 train_accs 
 [0.5400232018561485, 0.7815158546017015, 0.8122583139984533, 0.8225058004640372, 0.8333333333333334, 0.8420340293890178, 0.8547950502706884, 0.85015467904099, 0.8617556071152359, 0.8650425367362723, 0.8847641144624904, 0.8988785769528229, 0.901585460170147, 0.9124129930394432, 0.9052590873936582, 0.9085460170146945, 0.915893271461717, 0.9203402938901779, 0.9224671307037897, 0.9253673627223512, 0.9294276875483373, 0.9350348027842228, 0.9383217324052592, 0.9340680587780357, 0.9340680587780357, 0.9381283836040217, 0.9363882443928848, 0.9396751740139212, 0.9433488012374324, 0.9410286156225832, 0.9375483372003094, 0.9470224284609436, 0.9477958236658933, 0.9468290796597062, 0.9559164733178654, 0.955723124516628, 0.947215777262181, 0.949922660479505, 0.9516627996906419, 0.9508894044856923] 
 val_accs 
 [0.9101351351351352, 0.8986486486486487, 0.918918918918919, 0.9162162162162163, 0.918918918918919, 0.9162162162162163, 0.9162162162162163, 0.9108108108108108, 0.895945945945946, 0.9155405405405406, 0.9337837837837838, 0.9344594594594595, 0.9324324324324325, 0.9310810810810811, 0.9358108108108109, 0.9418918918918919, 0.9344594594594595, 0.9310810810810811, 0.9317567567567568, 0.9344594594594595, 0.943918918918919, 0.9412162162162163, 0.9466216216216217, 0.9425675675675677, 0.9418918918918919, 0.9432432432432433, 0.9398648648648649, 0.9391891891891893, 0.9472972972972974, 0.9445945945945946, 0.9466216216216217, 0.9452702702702703, 0.943918918918919, 0.9506756756756757, 0.9452702702702703, 0.945945945945946, 0.9486486486486487, 0.945945945945946, 0.9493243243243243, 0.9486486486486487] 
 val_losses 
 [0.8419418818241841, 0.6341026831317592, 0.4312080125550966, 0.3928585915952115, 0.363445619554133, 0.3326095214163935, 0.3254296551685075, 0.3216075179544655, 0.38086460248844045, 0.3034829188037563, 0.24471615856966455, 0.24382294710423497, 0.2470424309775636, 0.24441720762768307, 0.23545209108977705, 0.21907173491813042, 0.23810626240195454, 0.24483795955374435, 0.23965430187212455, 0.21880992292552381, 0.2027509658723264, 0.19595504322567503, 0.19259215085893064, 0.20126525394215777, 0.21661661577385824, 0.21002677824046162, 0.21647240358429987, 0.22216386505075403, 0.21028308518029548, 0.20890612229704858, 0.21155230737215763, 0.1989164054494452, 0.20430146198014956, 0.19705792129845232, 0.1958746011192734, 0.19876302829062617, 0.19841713885197768, 0.19616177291483491, 0.19360365133631874, 0.197606312423139] 
 test_accs 
 [0.9295393228530884] 
 test_losses 
 [0.24055314609190312]

 #############################################

  model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
inter3_size = 256
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Dropout(0.2),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Dropout(0.3),
                               nn.Linear(inter2_size, inter3_size),
                               nn.BatchNorm1d(inter3_size), 
                               nn.ReLU(inplace=True),
                               nn.Dropout(0.2),
                               nn.Linear(inter3_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max=40

train_losses: 
 [2.679459526754587, 1.5757378136014533, 1.157566984771115, 0.9487729509118353, 0.8486298129988196, 0.7502556582891194, 0.7044066471917078, 0.6389313446673329, 0.6055849921952268, 0.5811722057785808, 0.4856956016159943, 0.46563361434169454, 0.4421709919289296, 0.4000973826402486, 0.39638379739405843, 0.36300818180724437, 0.3728519936264345, 0.3720045142734318, 0.3568414505239798, 0.34231527565711245, 0.3165391244380306, 0.2750069823314861, 0.30854806753432945, 0.2749117853931005, 0.2603916535060349, 0.2620879550970808, 0.2668518638965794, 0.26335265195286744, 0.252562942321874, 0.2472664881656083, 0.21993419702027256, 0.2377013668406406, 0.23134306766962875, 0.20715040118308928, 0.21310243147662325, 0.20381832765869087, 0.2181803876820776, 0.20256909684257182, 0.20704137426149172, 0.23050089236939497] 
 train_accs 
 [0.42498066511987626, 0.7382057231245167, 0.7900232018561485, 0.8093580819798918, 0.8207656612529003, 0.8315931941221965, 0.8343000773395205, 0.8462877030162413, 0.844354215003867, 0.8602088167053364, 0.8822505800464038, 0.8892111368909513, 0.8882443928847642, 0.9048723897911833, 0.8986852281515855, 0.9098994586233565, 0.9069992266047952, 0.911446249033256, 0.9089327146171694, 0.9126063418406807, 0.9189868522815159, 0.9321345707656613, 0.9226604795050272, 0.9296210363495747, 0.938708430007734, 0.9375483372003094, 0.9338747099767982, 0.9340680587780357, 0.9365815931941223, 0.9371616395978345, 0.9460556844547564, 0.9398685228151586, 0.9404485692188709, 0.9503093580819799, 0.9489559164733179, 0.9506960556844548, 0.947215777262181, 0.9493426140757928, 0.9489559164733179, 0.940061871616396] 
 val_accs 
 [0.8628378378378379, 0.9101351351351352, 0.9101351351351352, 0.9304054054054055, 0.9013513513513514, 0.9236486486486487, 0.9033783783783784, 0.9060810810810811, 0.9094594594594595, 0.9067567567567568, 0.9256756756756758, 0.9331081081081082, 0.9398648648648649, 0.9324324324324325, 0.9391891891891893, 0.9364864864864866, 0.9418918918918919, 0.9405405405405406, 0.9385135135135135, 0.9283783783783784, 0.9418918918918919, 0.9378378378378379, 0.9398648648648649, 0.9398648648648649, 0.9445945945945946, 0.9358108108108109, 0.9378378378378379, 0.9351351351351351, 0.9385135135135135, 0.9337837837837838, 0.9405405405405406, 0.9337837837837838, 0.9432432432432433, 0.9344594594594595, 0.9385135135135135, 0.9364864864864866, 0.9364864864864866, 0.9412162162162163, 0.9378378378378379, 0.9405405405405406] 
 val_losses 
 [1.2832594104715296, 0.7198156640336321, 0.581401129348858, 0.4258877475519438, 0.4335643613660658, 0.35974229155360044, 0.3860946831268233, 0.35042596185529556, 0.3610621787406303, 0.31833325870133733, 0.2623345742354522, 0.24351768775566204, 0.23654874530998435, 0.2396809677819948, 0.244319414770281, 0.2397873281022987, 0.24261383254181695, 0.2348061744627115, 0.24912073290025866, 0.25618520330738376, 0.22412249836567286, 0.2274060747309311, 0.2261841608060373, 0.2273634802650761, 0.2129993802792317, 0.21936963915422156, 0.22948054139678542, 0.23295408330253653, 0.22732412753677045, 0.23823127964058438, 0.22343739955811887, 0.23638906020268396, 0.22686410413400546, 0.2265659959735097, 0.234731302148587, 0.23600541192132074, 0.234497982404522, 0.2235683298594243, 0.22391936718612104, 0.23634746935520623] 
 test_accs 
 [0.9403794407844543] 
 test_losses 
 [0.23370589792405363]

 ########################################################

model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
inter3_size = 256
dropout_rate = 0.3
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size), 
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size), 
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter2_size, inter3_size),
                               nn.BatchNorm1d(inter3_size), 
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter3_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max=40


train_losses: 
 [2.784465881806423, 1.6540922000255127, 1.229400831050681, 1.0064049275550193, 0.8898708687580932, 0.7963175066478106, 0.7525983300673713, 0.6822682196376679, 0.646479504198781, 0.5920346955504421, 0.5092815995585154, 0.4597285537644126, 0.4590462951446262, 0.44788364214391924, 0.43067809217951597, 0.4222645971863563, 0.4003951351769839, 0.3691405712728434, 0.395650293577206, 0.37757434242470544, 0.35414920718468906, 0.3232886782701128, 0.3121749318945989, 0.30452661162093914, 0.2879858792796212, 0.28876428521610653, 0.29192553286578243, 0.27590272805530347, 0.28618511334004, 0.2761211365991476, 0.24195251306727794, 0.24686610495868988, 0.2523243326783088, 0.23678201009438007, 0.23149764344199905, 0.2286101528497417, 0.24456826059834863, 0.25095569195437595, 0.21724186717818528, 0.22988732227132197] 
 train_accs 
 [0.36388244392884767, 0.7339520494972932, 0.7780355761794278, 0.8066511987625677, 0.8151585460170148, 0.8250193348801238, 0.8315931941221965, 0.839907192575406, 0.8441608662026295, 0.8557617942768755, 0.8760634184068059, 0.889984532095901, 0.8915313225058005, 0.8897911832946637, 0.8959783449342614, 0.8953982985305492, 0.9006187161639598, 0.9120262954369683, 0.9046790409899459, 0.9069992266047952, 0.9120262954369683, 0.9178267594740913, 0.9240139211136892, 0.9276875483372004, 0.9298143851508122, 0.9286542923433875, 0.9280742459396752, 0.9325212683681362, 0.9300077339520495, 0.9321345707656613, 0.9412219644238207, 0.9419953596287703, 0.9396751740139212, 0.945862335653519, 0.9445088940448569, 0.945862335653519, 0.9425754060324827, 0.9383217324052592, 0.9503093580819799, 0.9445088940448569] 
 val_accs 
 [0.8810810810810812, 0.9168918918918919, 0.8979729729729731, 0.893918918918919, 0.9, 0.9135135135135135, 0.9067567567567568, 0.9141891891891892, 0.9040540540540541, 0.9236486486486487, 0.9290540540540541, 0.9310810810810811, 0.9344594594594595, 0.9256756756756758, 0.9358108108108109, 0.9317567567567568, 0.9331081081081082, 0.9351351351351351, 0.9317567567567568, 0.9324324324324325, 0.9371621621621622, 0.9364864864864866, 0.9405405405405406, 0.9391891891891893, 0.9405405405405406, 0.9405405405405406, 0.9452702702702703, 0.9398648648648649, 0.9452702702702703, 0.9466216216216217, 0.943918918918919, 0.9432432432432433, 0.9405405405405406, 0.945945945945946, 0.9398648648648649, 0.9412162162162163, 0.945945945945946, 0.9472972972972974, 0.9466216216216217, 0.9418918918918919] 
 val_losses 
 [1.3292777725168177, 0.7852442973368877, 0.6208444601780659, 0.5315523959494926, 0.46343583206872685, 0.36271839286829977, 0.35766313398206556, 0.33770125701620773, 0.3465550886819492, 0.3010043988356719, 0.26925340504259676, 0.25619771818856935, 0.2359964506046192, 0.2652867927543215, 0.2392720168506777, 0.22783604103165703, 0.2294689980713097, 0.24115240321167417, 0.24763877865027736, 0.25116761278461763, 0.22163510209805257, 0.2181304576831895, 0.21370293063086432, 0.2223996615087664, 0.22095093614346273, 0.208974505437387, 0.21237629088195595, 0.21672773071237514, 0.22285352056292262, 0.20952865690798372, 0.21157785235224544, 0.21859820920067866, 0.2071089900728013, 0.20464116882633518, 0.21230272231875238, 0.21497670815049394, 0.2068969325842084, 0.2047855033262356, 0.20962496696895844, 0.2059113794887388] 
 test_accs 
 [0.9308943152427673] 
 test_losses 
 [0.2494336976026132]

 ##############################################
 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
inter3_size = 256
dropout_rate = 0.3
max_iters = 40
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter2_size, inter3_size),
                               nn.BatchNorm1d(inter3_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter3_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
#laod data
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64

train_losses: 
 [2.5565751567886306, 1.4422106102097432, 1.0733572098974655, 0.8567264619854561, 0.7067873662788556, 0.6600033253638761, 0.6109505489825834, 0.5681121215650672, 0.5214322801947318, 0.49627555527617007, 0.43571592997601116, 0.3848186416950506, 0.35987245695404735, 0.3404751411723427, 0.3364295349135845, 0.3011992632052, 0.31980709957458764, 0.2975081819623179, 0.29952097427725144, 0.27613729655696545, 0.2566011354430922, 0.25509628956620306, 0.2483059526503962, 0.2381107264586594, 0.2239570739259115, 0.23459142181454753, 0.22976361211657248, 0.21003188295412323, 0.20865985953983002, 0.21529949011031915, 0.2000964464474259, 0.1981648758964214, 0.19336007280766457, 0.18205243916080058, 0.1953006953185414, 0.1997362594224645, 0.1885028368313001, 0.159564491986583, 0.18596941886119667, 0.17919748886693657] 
 train_accs 
 [0.4766047950502707, 0.7946635730858469, 0.8221191028615623, 0.8447409126063419, 0.8681361175560712, 0.8654292343387472, 0.8634957463263728, 0.8739365815931942, 0.8781902552204177, 0.8874709976798144, 0.8973317865429234, 0.908739365815932, 0.915893271461717, 0.9249806651198763, 0.9236272235112143, 0.931554524361949, 0.9251740139211138, 0.9313611755607115, 0.925754060324826, 0.9334880123743233, 0.9389017788089714, 0.9392884764114463, 0.9404485692188709, 0.9441221964423822, 0.9477958236658933, 0.9443155452436195, 0.9476024748646559, 0.9537896365042537, 0.9524361948955917, 0.9477958236658933, 0.9520494972931168, 0.9541763341067286, 0.9547563805104409, 0.9555297757153907, 0.954369682907966, 0.9534029389017789, 0.95707656612529, 0.9640371229698377, 0.9551430781129158, 0.9603634957463264] 
 val_accs 
 [0.8925675675675676, 0.9081081081081082, 0.9270270270270271, 0.9283783783783784, 0.9222972972972974, 0.9263513513513514, 0.9304054054054055, 0.925, 0.9297297297297298, 0.922972972972973, 0.9445945945945946, 0.9412162162162163, 0.9445945945945946, 0.9378378378378379, 0.9391891891891893, 0.9445945945945946, 0.9452702702702703, 0.9398648648648649, 0.9466216216216217, 0.9358108108108109, 0.9432432432432433, 0.943918918918919, 0.945945945945946, 0.9425675675675677, 0.9466216216216217, 0.9445945945945946, 0.9452702702702703, 0.9493243243243243, 0.9486486486486487, 0.9486486486486487, 0.947972972972973, 0.9486486486486487, 0.9486486486486487, 0.9527027027027027, 0.9500000000000001, 0.9506756756756757, 0.9493243243243243, 0.9513513513513514, 0.9472972972972974, 0.9493243243243243] 
 val_losses 
 [1.2313347642486159, 0.7509988191965464, 0.5290998247829644, 0.4209056858275388, 0.3635781606306901, 0.3212857703502114, 0.3130387344875851, 0.2811826751038835, 0.27306215408686046, 0.2939933651202434, 0.2158617144500887, 0.23143523899284568, 0.20727060489557886, 0.22404390138548774, 0.23536894192566743, 0.21882647676645098, 0.21890435476560852, 0.21558370525772508, 0.21309899185356257, 0.22774284274594203, 0.20115845058415388, 0.19063581683345743, 0.19321340636123677, 0.1981445428890151, 0.1912815917182613, 0.19885801397566055, 0.1939023242608921, 0.19155453679126663, 0.19454727105393604, 0.182952194117211, 0.18568427337182536, 0.18290979578285604, 0.19289218670613056, 0.18309419019198095, 0.19131618214620127, 0.18638673561650354, 0.1921749626462524, 0.18530478090853306, 0.18532528051653424, 0.18429360272916587] 
 test_accs 
 [0.9417344331741333] 
 test_losses 
 [0.20789561297512313]

 #############################################

 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
inter3_size = 256
dropout_rate = 0.4
max_iters = 40
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter2_size, inter3_size),
                               nn.BatchNorm1d(inter3_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter3_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)

#laod data
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max+40

train_losses: 
 [2.888382294154038, 1.8502312560276937, 1.355286630474129, 1.0890431577442048, 0.917323688481634, 0.7753539522857695, 0.7259057363796307, 0.6548688081651349, 0.6142359656920658, 0.5880322764755125, 0.5046084641672711, 0.4383547861541046, 0.4332734280469707, 0.4144394196748549, 0.3965939753570026, 0.38043531176201245, 0.3524825408167371, 0.34525768342445917, 0.34748679950360817, 0.3461737832355573, 0.3117660034537223, 0.29928981893669243, 0.2794281917538462, 0.2782317775907391, 0.28207552303939665, 0.25664185143125584, 0.2634632384371407, 0.24141683766570832, 0.24375001086989578, 0.2581420141140435, 0.24575854246688275, 0.234690564137877, 0.2169061225694183, 0.2295183391300911, 0.21362313311273334, 0.20801316421804553, 0.2302342516594125, 0.21749219440690143, 0.20685817230973977, 0.2058585407089929] 
 train_accs 
 [0.3323665893271462, 0.7059164733178654, 0.7917633410672854, 0.8254060324825987, 0.8379737045630318, 0.8625290023201857, 0.8546017014694509, 0.8652358855375097, 0.8687161639597835, 0.8691028615622584, 0.8919180201082754, 0.9089327146171694, 0.9089327146171694, 0.9118329466357309, 0.9135730858468678, 0.9213070378963651, 0.924400618716164, 0.9292343387470998, 0.9224671307037897, 0.9245939675174014, 0.9352281515854602, 0.9379350348027843, 0.9367749419953597, 0.9419953596287703, 0.9375483372003094, 0.9456689868522815, 0.941415313225058, 0.9506960556844548, 0.9474091260634184, 0.9412219644238207, 0.9468290796597062, 0.9516627996906419, 0.9532095901005414, 0.949922660479505, 0.9534029389017789, 0.9553364269141532, 0.9477958236658933, 0.9522428460943543, 0.9541763341067286, 0.9534029389017789] 
 val_accs 
 [0.8135135135135135, 0.9074324324324324, 0.9182432432432432, 0.9182432432432432, 0.9310810810810811, 0.9256756756756758, 0.9243243243243244, 0.9101351351351352, 0.9087837837837839, 0.9236486486486487, 0.9351351351351351, 0.9466216216216217, 0.9432432432432433, 0.9472972972972974, 0.9405405405405406, 0.943918918918919, 0.9493243243243243, 0.9418918918918919, 0.9486486486486487, 0.9391891891891893, 0.9445945945945946, 0.9466216216216217, 0.9506756756756757, 0.9554054054054054, 0.9500000000000001, 0.9432432432432433, 0.9500000000000001, 0.9554054054054054, 0.9520270270270271, 0.9506756756756757, 0.9500000000000001, 0.9520270270270271, 0.9520270270270271, 0.9500000000000001, 0.9520270270270271, 0.947972972972973, 0.9527027027027027, 0.9513513513513514, 0.9500000000000001, 0.943918918918919] 
 val_losses 
 [1.6701261629929414, 1.053560083621257, 0.6278192407376058, 0.5553343837325637, 0.41482252422216775, 0.3561255851307431, 0.3431514023123561, 0.3837593306560774, 0.3456429691330807, 0.31147940070242497, 0.23523525386243252, 0.2209502152897216, 0.22498277039141268, 0.22034625471443745, 0.23273748382925988, 0.2080175123303323, 0.21216106414794922, 0.21616973321180086, 0.21931689112774425, 0.21117065242818883, 0.20145134149572333, 0.1949100995385969, 0.17773625954381517, 0.18501880499156745, 0.20212151456523586, 0.20792497217252448, 0.19019037358261442, 0.1855316472919406, 0.1833553283601194, 0.1822549481146239, 0.1842950514844946, 0.1826037002576364, 0.1819902444308674, 0.18466517071466187, 0.17890065944678074, 0.18488877628602693, 0.18022523812345556, 0.1762614986683066, 0.18099007493740804, 0.1956963797980869] 
 test_accs 
 [0.9390243887901306] 
 test_losses 
 [0.19927852392842776]

 ################################

 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
inter3_size = 256
inter4_size = 128
dropout_rate = 0.3
max_iters = 40
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter2_size, inter3_size),
                               nn.BatchNorm1d(inter3_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter3_size, inter4_size),
                               nn.BatchNorm1d(inter4_size),
                               nn.ReLU(inplace=True),
                               nn.Dropout(dropout_rate),
                               nn.Linear(inter4_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=1e-4)
scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64
iter_max=40

train_losses: 
 [2.688328801433153, 1.4902839453203771, 1.0491397120836439, 0.8510921591488041, 0.7121588922892996, 0.6259986263140171, 0.5725422522308102, 0.5148828749682492, 0.4983867251955993, 0.46765688112421916, 0.43528056036384183, 0.414388001287804, 0.4069742191833576, 0.4020823303664828, 0.39457133972451197, 0.3702834863719881, 0.362590563223515, 0.3606348326753851, 0.33800825492780706, 0.33311519757408736, 0.3226685872372047, 0.3287898961855106, 0.32131666113310603, 0.3511539569033824, 0.3281729677022195, 0.3197806989003408, 0.30324063507144244, 0.3179946784952861, 0.3277659315128983, 0.3058420441820007, 0.3026486556726376, 0.3090064568705828, 0.31244667467919784, 0.3136114110019165, 0.31921873266440626, 0.3159143003676164, 0.31518138623569514, 0.30970426382063343, 0.32649514602305624, 0.31699669752947046] 
 train_accs 
 [0.3776102088167054, 0.7463263727764888, 0.8186388244392885, 0.8383604021655067, 0.8654292343387472, 0.8816705336426914, 0.8892111368909513, 0.9023588553750967, 0.8975251353441609, 0.9023588553750967, 0.911446249033256, 0.9170533642691415, 0.9151198762567673, 0.9147331786542924, 0.9187935034802784, 0.924400618716164, 0.9263341067285383, 0.925754060324826, 0.9336813611755608, 0.9307811291569993, 0.9348414539829853, 0.9365815931941223, 0.9352281515854602, 0.9240139211136892, 0.932907965970611, 0.9340680587780357, 0.9385150812064965, 0.9350348027842228, 0.9305877803557618, 0.9367749419953597, 0.9402552204176334, 0.9421887084300078, 0.9331013147718484, 0.9367749419953597, 0.9338747099767982, 0.9350348027842228, 0.9363882443928848, 0.9365815931941223, 0.9292343387470998, 0.9309744779582367] 
 val_accs 
 [0.8831081081081081, 0.9155405405405406, 0.9391891891891893, 0.9418918918918919, 0.9405405405405406, 0.9466216216216217, 0.9500000000000001, 0.9500000000000001, 0.945945945945946, 0.9513513513513514, 0.9533783783783785, 0.9567567567567568, 0.9567567567567568, 0.9513513513513514, 0.9533783783783785, 0.9560810810810811, 0.9560810810810811, 0.9527027027027027, 0.9560810810810811, 0.9560810810810811, 0.9540540540540541, 0.9547297297297298, 0.9533783783783785, 0.9540540540540541, 0.9554054054054054, 0.9540540540540541, 0.9547297297297298, 0.9567567567567568, 0.9560810810810811, 0.9560810810810811, 0.9540540540540541, 0.9554054054054054, 0.9540540540540541, 0.9520270270270271, 0.9554054054054054, 0.9527027027027027, 0.9547297297297298, 0.9533783783783785, 0.9560810810810811, 0.9567567567567568] 
 val_losses 
 [1.2024304370622376, 0.6813748668979954, 0.4918543867162756, 0.3713371102874343, 0.3008195214577623, 0.2692551080439542, 0.259768676516172, 0.24400261624439343, 0.24192262014021745, 0.22233541350106936, 0.2108375837674012, 0.20759763290753236, 0.2088466134023022, 0.2092810860759503, 0.2034645302875622, 0.1937651262895481, 0.1944925549867991, 0.1961953085822028, 0.19019425672453802, 0.1913763968525706, 0.1899655244640402, 0.1858251565614262, 0.1887411999138626, 0.1854081266635173, 0.18670565872579006, 0.18259053043014295, 0.18674265776534338, 0.18489999712721722, 0.1832015830922771, 0.18299751712663753, 0.18476918790791486, 0.18102101019105396, 0.1834633893257863, 0.18379986141179058, 0.18180233707299104, 0.18058801824982101, 0.17927319181931986, 0.1819422773412756, 0.17956827315124305, 0.17986417058351878] 
 test_accs 
 [0.955284595489502] 
 test_losses 
 [0.21612556533115665]

 ##############################

 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
inter2_size = 512
#dropout_rate = 0.5
max_iters = 40
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size),
                               nn.ReLU(inplace=True),
                               #nn.Dropout(dropout_rate),
                               nn.Linear(inter1_size, inter2_size),
                               nn.BatchNorm1d(inter2_size),
                               nn.ReLU(inplace=True), 
                               #nn.Dropout(dropout_rate),
                               nn.Linear(inter2_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-5)
scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)

data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64

train_losses: 
 [1.7034079987967743, 0.7341726533866906, 0.5457479191766814, 0.4943706120342039, 0.43700343386571905, 0.38668812296230115, 0.3270648720415636, 0.3170023193584333, 0.294480753378267, 0.2916238533487084, 0.2751353420864586, 0.26428607738903115, 0.2541495888434172, 0.24184135598262335, 0.2449562051502753, 0.21198982797845425, 0.21211654918191974, 0.24120313030568924, 0.22163149080623146, 0.21414599677710597, 0.20911853044234038, 0.1934128453910397, 0.1861182297050538, 0.19241025124237876, 0.18964897483379825, 0.19425402337372627, 0.18958493028835832, 0.19960267985872032, 0.1904359090632463, 0.18824109568765526, 0.17772434648394309, 0.19048478476824174, 0.18743741150429705, 0.19125620789151734, 0.19093396411510005, 0.1982108718281279, 0.1813670612658444, 0.1876761555060894, 0.18404481709233939, 0.181377299723474] 
 train_accs 
 [0.6844547563805105, 0.8493812838360403, 0.8749033255993813, 0.8834106728538283, 0.8946249033255994, 0.9062258313998454, 0.9205336426914154, 0.9189868522815159, 0.9263341067285383, 0.9286542923433875, 0.9313611755607115, 0.932907965970611, 0.9367749419953597, 0.9408352668213458, 0.9427687548337201, 0.9491492652745553, 0.9464423820572313, 0.9421887084300078, 0.9447022428460944, 0.9487625676720804, 0.9495359628770302, 0.9528228924980665, 0.9564965197215778, 0.9564965197215778, 0.95707656612529, 0.9524361948955917, 0.955723124516628, 0.9524361948955917, 0.9514694508894045, 0.9534029389017789, 0.955723124516628, 0.9514694508894045, 0.9534029389017789, 0.9545630317092034, 0.9532095901005414, 0.9514694508894045, 0.9566898685228152, 0.9534029389017789, 0.9555297757153907, 0.9590100541376644] 
 val_accs 
 [0.9243243243243244, 0.9270270270270271, 0.9385135135135135, 0.9418918918918919, 0.947972972972973, 0.9560810810810811, 0.9506756756756757, 0.9547297297297298, 0.9554054054054054, 0.9500000000000001, 0.9567567567567568, 0.9567567567567568, 0.9527027027027027, 0.9547297297297298, 0.9533783783783785, 0.9527027027027027, 0.9547297297297298, 0.9560810810810811, 0.9527027027027027, 0.9554054054054054, 0.9540540540540541, 0.9560810810810811, 0.9554054054054054, 0.9540540540540541, 0.9533783783783785, 0.9520270270270271, 0.9533783783783785, 0.9554054054054054, 0.9533783783783785, 0.9533783783783785, 0.9547297297297298, 0.9506756756756757, 0.9560810810810811, 0.9540540540540541, 0.9527027027027027, 0.9547297297297298, 0.9554054054054054, 0.9547297297297298, 0.9527027027027027, 0.9540540540540541] 
 val_losses 
 [0.5140871537698282, 0.3337452949704351, 0.295055572044205, 0.23745339979996552, 0.22406278520419792, 0.18781613075249903, 0.18650226399705216, 0.17793750807240202, 0.17744508981704712, 0.18208279939922126, 0.17087449741524618, 0.16912850900679022, 0.17600969390289203, 0.16224092696164105, 0.16741416226770428, 0.1623861337030256, 0.16636628608244497, 0.16202866910277186, 0.16529305988066906, 0.1586485204161019, 0.16109272713798123, 0.16217629784667814, 0.16249638499843108, 0.16576298338335912, 0.16262553233552623, 0.1659949078753188, 0.1611521985079791, 0.1650242483293688, 0.1666096629323186, 0.16434281323407146, 0.15845531967242021, 0.1620704240090138, 0.16207714038523469, 0.15629152056534548, 0.16369888863048038, 0.1620994173191689, 0.16121760071129412, 0.1602368631828073, 0.16318915850810103, 0.1619205807310504] 
 test_accs 
 [0.9579945802688599] 
 test_losses 
 [0.1856114699386646]

 ############################################
model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
#inter2_size = 512
#dropout_rate = 0.5
max_iters = 40
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size),
                               nn.ReLU(inplace=True),
                               #nn.Dropout(dropout_rate),
                               #nn.Linear(inter1_size, inter2_size),
                               #nn.BatchNorm1d(inter2_size),
                               #nn.ReLU(inplace=True), 
                               #nn.Dropout(dropout_rate),
                               nn.Linear(inter1_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-5)
scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64



 train_losses: 
 [1.453412311075274, 0.6020581323973264, 0.46475341266103243, 0.3930612126709598, 0.38511208027071114, 0.3145853119217326, 0.2648743801078221, 0.2601765373697229, 0.2723218823530281, 0.2502509969223956, 0.2210964156575472, 0.2395510813199727, 0.20998465478973433, 0.19081404784439335, 0.1876968683909743, 0.20663864667435902, 0.1918539638182311, 0.17452505860140594, 0.1882305742174456, 0.1735559713674532, 0.16598759447523354, 0.1791558688634694, 0.16464620066859975, 0.17537749618038317, 0.16836168965625836, 0.17422920976004116, 0.16978894438009712, 0.1826087979388071, 0.17284222420849546, 0.1685268095041188, 0.16317376538200704, 0.16367463255265105, 0.17102751304083616, 0.16788618099477434, 0.16282985992700852, 0.16010533560756005, 0.18203257965838734, 0.16445491830000836, 0.16003825058562757, 0.1571340583385835] 
 train_accs 
 [0.7078499613302398, 0.8503480278422274, 0.8714230471771075, 0.8953982985305492, 0.8953982985305492, 0.9122196442382058, 0.930201082753287, 0.9294276875483373, 0.9261407579273009, 0.9352281515854602, 0.9404485692188709, 0.934261407579273, 0.9470224284609436, 0.9456689868522815, 0.9474091260634184, 0.9447022428460944, 0.9510827532869297, 0.9551430781129158, 0.948569218870843, 0.9576566125290024, 0.9572699149265275, 0.954369682907966, 0.9564965197215778, 0.9555297757153907, 0.9547563805104409, 0.9516627996906419, 0.954369682907966, 0.9497293116782677, 0.9576566125290024, 0.9580433101314773, 0.9588167053364269, 0.9549497293116783, 0.9539829853054912, 0.9563031709203403, 0.95707656612529, 0.9561098221191029, 0.954369682907966, 0.9539829853054912, 0.9580433101314773, 0.960170146945089] 
 val_accs 
 [0.9310810810810811, 0.9364864864864866, 0.9344594594594595, 0.9520270270270271, 0.9513513513513514, 0.9547297297297298, 0.9527027027027027, 0.9560810810810811, 0.9500000000000001, 0.9567567567567568, 0.9635135135135136, 0.9628378378378379, 0.9648648648648649, 0.9608108108108109, 0.9547297297297298, 0.9614864864864865, 0.9594594594594595, 0.9574324324324325, 0.9594594594594595, 0.9608108108108109, 0.9608108108108109, 0.9594594594594595, 0.9581081081081082, 0.9574324324324325, 0.9587837837837838, 0.9601351351351352, 0.9608108108108109, 0.9587837837837838, 0.9587837837837838, 0.9594594594594595, 0.9594594594594595, 0.9594594594594595, 0.9601351351351352, 0.9581081081081082, 0.9581081081081082, 0.9567567567567568, 0.9614864864864865, 0.9587837837837838, 0.9581081081081082, 0.9601351351351352] 
 val_losses 
 [0.3369669978683059, 0.26322329145025564, 0.23189986783104974, 0.18505598258327793, 0.1746338474186691, 0.164870100035458, 0.1571960434317589, 0.15891551133748646, 0.16327116615264803, 0.15530855438193758, 0.14781416387272042, 0.14236274840863974, 0.1438014880225465, 0.14816585960420403, 0.14792353413193612, 0.14712011844322487, 0.14440154757954785, 0.14183601280926048, 0.13850297049896138, 0.1384636370112767, 0.13954011515991108, 0.1407294329759237, 0.14345745072775595, 0.1436876425871978, 0.1451378373680888, 0.1472579566208092, 0.14444585675121965, 0.14376233733586363, 0.1421741075008302, 0.13949979829627115, 0.142600872468304, 0.140005721272649, 0.14298078884949555, 0.1392703852138004, 0.1398492813211035, 0.13999909624658727, 0.14237130628647032, 0.14143792761338725, 0.14149976743234172, 0.13900231295139404] 
 test_accs 
 [0.9525745511054993] 
 test_losses 
 [0.1613242228018236]


 ###################################################

 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
#inter2_size = 512
#dropout_rate = 0.5
max_iters = 40
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               #nn.BatchNorm1d(inter1_size),
                               nn.ReLU(inplace=True),
                               #nn.Dropout(dropout_rate),
                               #nn.Linear(inter1_size, inter2_size),
                               #nn.BatchNorm1d(inter2_size),
                               #nn.ReLU(inplace=True), 
                               #nn.Dropout(dropout_rate),
                               nn.Linear(inter1_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-5)
scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64

model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024

max_iters = 40
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-5)
scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)

#laod data
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64

train_losses: 
 [2.1841499421915525, 0.6910953415703239, 0.49336882243300256, 0.4018975244366837, 0.37508056058684525, 0.31199265773316637, 0.3004254424701065, 0.2904636579157305, 0.2588449798391848, 0.2366545830967808, 0.2236389345377799, 0.20164146567626418, 0.23521591468274086, 0.22226822115797823, 0.18667149961524848, 0.20175736739205835, 0.17723034187425316, 0.1841820327929536, 0.17854434444244205, 0.18051970917198515, 0.18588104890479382, 0.1886704694436487, 0.18347065766145348, 0.1737130445536955, 0.17999552988950726, 0.17963062313205957, 0.16452906536023376, 0.17845540998499243, 0.17470105115701687, 0.1806890265893678, 0.15603572858550802, 0.17337583857087874, 0.18459174031217432, 0.17513002853981766, 0.15550615501929324, 0.17973841370673302, 0.1863001655536572, 0.1682674856503528, 0.16958400709677002, 0.16449036371979894] 
 train_accs 
 [0.5783062645011601, 0.8339133797370457, 0.8642691415313225, 0.8870843000773395, 0.8938515081206497, 0.9077726218097448, 0.9141531322505801, 0.919953596287703, 0.9265274555297758, 0.932907965970611, 0.9375483372003094, 0.9408352668213458, 0.932907965970611, 0.9369682907965972, 0.9456689868522815, 0.9431554524361949, 0.9481825212683682, 0.9468290796597062, 0.9493426140757928, 0.947215777262181, 0.9474091260634184, 0.948569218870843, 0.948569218870843, 0.9491492652745553, 0.949922660479505, 0.9524361948955917, 0.9555297757153907, 0.9495359628770302, 0.9528228924980665, 0.9487625676720804, 0.9563031709203403, 0.9524361948955917, 0.9493426140757928, 0.9497293116782677, 0.9549497293116783, 0.9464423820572313, 0.947215777262181, 0.9524361948955917, 0.9528228924980665, 0.954369682907966] 
 val_accs 
 [0.8945945945945947, 0.9263513513513514, 0.9195945945945947, 0.9398648648648649, 0.9405405405405406, 0.9533783783783785, 0.9540540540540541, 0.9500000000000001, 0.9540540540540541, 0.9500000000000001, 0.9554054054054054, 0.9486486486486487, 0.9493243243243243, 0.9493243243243243, 0.9560810810810811, 0.9520270270270271, 0.9493243243243243, 0.9540540540540541, 0.9513513513513514, 0.9520270270270271, 0.9540540540540541, 0.9547297297297298, 0.9554054054054054, 0.9574324324324325, 0.9527027027027027, 0.9547297297297298, 0.9560810810810811, 0.9560810810810811, 0.9540540540540541, 0.9547297297297298, 0.9567567567567568, 0.9547297297297298, 0.9540540540540541, 0.9527027027027027, 0.9540540540540541, 0.9520270270270271, 0.9547297297297298, 0.9554054054054054, 0.9540540540540541, 0.9533783783783785] 
 val_losses 
 [0.5426726280031977, 0.2851512441764007, 0.24160748816825248, 0.1825231959690919, 0.19885010320089153, 0.16290554758664724, 0.1570859582037539, 0.16454809372489518, 0.15399293581376206, 0.15513288203526188, 0.1509407699913592, 0.15061090344915518, 0.1506900404277887, 0.1480421050879601, 0.14804035733277734, 0.14330361634492875, 0.15445194945142077, 0.1529214747048713, 0.149636015457076, 0.15252387708908802, 0.1464771236519556, 0.14429631660113462, 0.14596433633485356, 0.14445251901004766, 0.15023306087666266, 0.14666222011720811, 0.15010821690430512, 0.14703973821691566, 0.14625461435801274, 0.14226046434125383, 0.146623706132979, 0.1454766357267225, 0.14639805482851492, 0.14591935246780113, 0.1452536404132843, 0.14273135106305818, 0.14238486900875294, 0.14248798828370668, 0.1445947302706741, 0.14464488287229796] 
 test_accs 
 [0.9485095143318176] 
 test_losses 
 [0.15456367774707516]


 #########################################################
 model_tuned = models.resnet50(weights="IMAGENET1K_V1")

num_features = model_tuned.fc.in_features
output_size = 37
inter1_size = 1024
max_iters = 40
model_tuned.fc = nn.Sequential(nn.Linear(num_features, inter1_size),
                               nn.BatchNorm1d(inter1_size),
                               nn.ReLU(inplace=True),
                               nn.Linear(inter1_size, output_size))
model_tuned = model_tuned.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_tuned.parameters(), lr=5e-5)
scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}
BatchSize = 64

train_losses: 
 [1.5211664866497603, 0.586240896953692, 0.4467722602989539, 0.4050643500300774, 0.39553956826896697, 0.3102390269207936, 0.28279732556095993, 0.25900098109835357, 0.27202250359598645, 0.24401934206347453, 0.23011304962478307, 0.22017980594553876, 0.21063115694959866, 0.20103803690744756, 0.2106770145528923, 0.19137063481875935, 0.18854343682550592, 0.19051455855600058, 0.20315036892153363, 0.18760388579049594, 0.1847912933207812, 0.16558254668625952, 0.1754643084785317, 0.17253237898185653, 0.1678648739131218, 0.1779092505332212, 0.16024596326496834, 0.1660285653735166, 0.16844031599631903, 0.1616444932520159, 0.17833841660644137, 0.1765910671694004, 0.17824362296746482, 0.15910690469697567, 0.15546742750062376, 0.15860144993360892, 0.1790108866499822, 0.16961902458356132, 0.1569502851583657, 0.17137376369428745] 
 train_accs 
 [0.6931554524361949, 0.8547950502706884, 0.8810904872389792, 0.8946249033255994, 0.8940448569218872, 0.9191802010827533, 0.9228538283062645, 0.931554524361949, 0.9284609435421501, 0.930201082753287, 0.9358081979891725, 0.9427687548337201, 0.9396751740139212, 0.9476024748646559, 0.9441221964423822, 0.948569218870843, 0.9505027068832174, 0.9505027068832174, 0.9441221964423822, 0.9479891724671308, 0.9522428460943543, 0.9572699149265275, 0.9535962877030163, 0.9514694508894045, 0.9524361948955917, 0.9514694508894045, 0.95707656612529, 0.9574632637277649, 0.9555297757153907, 0.9566898685228152, 0.9505027068832174, 0.9512761020881672, 0.9512761020881672, 0.9597834493426142, 0.9607501933488013, 0.9590100541376644, 0.9526295436968292, 0.95707656612529, 0.9578499613302398, 0.9545630317092034] 
 val_accs 
 [0.9216216216216216, 0.9486486486486487, 0.9486486486486487, 0.9527027027027027, 0.9527027027027027, 0.9540540540540541, 0.9554054054054054, 0.9594594594594595, 0.9581081081081082, 0.9527027027027027, 0.9533783783783785, 0.9574324324324325, 0.9554054054054054, 0.9574324324324325, 0.9547297297297298, 0.9547297297297298, 0.9581081081081082, 0.9554054054054054, 0.9567567567567568, 0.9554054054054054, 0.9554054054054054, 0.9574324324324325, 0.9587837837837838, 0.9581081081081082, 0.9587837837837838, 0.9594594594594595, 0.9574324324324325, 0.9581081081081082, 0.9601351351351352, 0.9581081081081082, 0.9587837837837838, 0.9581081081081082, 0.9594594594594595, 0.9587837837837838, 0.9608108108108109, 0.9567567567567568, 0.9574324324324325, 0.9581081081081082, 0.9581081081081082, 0.9594594594594595] 
 val_losses 
 [0.36409655906058647, 0.2301415404757938, 0.20702716275244146, 0.18839166776554003, 0.17241901368708223, 0.16564530025462845, 0.15737014549809533, 0.1518549742730888, 0.16017916846919705, 0.1590385672007058, 0.1532790407941148, 0.14214885891289325, 0.15030605896199878, 0.14763296617043986, 0.14648506953506857, 0.14946518161812344, 0.14188840459478466, 0.14078370759616027, 0.14412563020313107, 0.14566555516542615, 0.14207290201573758, 0.14673076166544816, 0.14303197184124508, 0.14300735383420377, 0.14301490135792944, 0.14264693147427326, 0.14330209857104598, 0.14112652987241744, 0.1409410896182463, 0.14319611828069428, 0.14438517386647495, 0.1412751555241443, 0.13768169969521665, 0.13980981786735355, 0.13977447136028393, 0.14314128547101407, 0.141680812110772, 0.14298026114702225, 0.14182911716854651, 0.1398670298424927] 
 test_accs 
 [0.9512195587158203] 
 test_losses 
 [0.15973714345354376]